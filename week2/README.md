# Semana 2 - LLM Zoomcamp

Este documento recopila mis apuntes y recursos para la **Semana 2** del curso LLM Zoomcamp.

## üìù Notas de la teor√≠a

### Busqueda Vectorial

La b√∫squeda vectorial permite encontrar objetos similares transform√°ndolos en vectores de alta dimensi√≥n y compar√°ndolos en funci√≥n de su cercan√≠a en ese espacio. Qdrant es una base de datos open‚Äësource escrita en Rust, dise√±ada para realizar esa b√∫squeda de manera r√°pida y escalable

**Vectores**

En aprendizaje autom√°tico, un vector es una representaci√≥n num√©rica de un objeto complejo (texto, imagen, usuario, etc.) en un espacio multidimensional. Si imaginas cada dato como una canci√≥n, el vector ser√≠a la partitura que resume su melod√≠a sem√°ntica.

**M√©tricas de similitud**

Comparar vectores es medir distancias:
- Similitud del coseno: compara la orientaci√≥n de dos vectores (√°ngulo).
- Distancia Euclidiana: mide la distancia ‚Äúdirecta‚Äù en el espacio.
- Producto escalar: correlaciona vectores en funci√≥n de su producto escalar.

**B√∫squeda sem√°ntica y disimilitud**

- B√∫squeda de similitud sem√°ntica: encuentra vectores cercanos al vector de consulta, como buscar estrellas de la misma constelaci√≥n.
- B√∫squeda por disimilitud: selecciona vectores lejanos, √∫til para detecci√≥n de anomal√≠as.

**B√∫squeda de diversidad**

Algunos casos requieren variedad. Una manera ser√≠a filtrar resultados muy cercanos entre s√≠ (‚Äúvecinos ruidosos‚Äù), garantizando que los resultados sean sem√°nticamente distintos entre s√≠.


**Recomendaciones basadas en vectores**
* Recomendaciones de caracter√≠sticas vectoriales: almacenamos vectores de usuarios y productos. Luego, al comparar vectores similares, sugerimos √≠tems que est√°n cerca en ese espacio.

* Recomendaciones de distancia relativa: no se trata solo de encontrar los m√°s similares, sino de medir "lo suficientemente cerca" respecto al promedio, usando filtros din√°micos y normalizaci√≥n dentro del espacio vectorial.

**Descubrimiento**

Encuentros inesperados son posibles gracias a la diversidad vectorial: descubrir relaciones no evidentes entre documentos, temas o productos.

### Qdrant: Motor de B√∫squeda Vectorial Sem√°ntica

Qdrant (Quadrant) es un **motor de base de datos vectorial de alto rendimiento** dise√±ado para b√∫squedas sem√°nticas, recuperaci√≥n de informaci√≥n por similitud y aplicaciones de inteligencia artificial. Est√° optimizado para manejar **incrustaciones vectoriales** generadas por modelos de machine learning y proporciona una API eficiente para realizar b√∫squedas de vecinos m√°s cercanos (k-NN) de manera precisa, r√°pida y escalable.

Qdrant permite almacenar vectores densos (embeddings) junto con **metadatos** estructurados, habilitando b√∫squedas h√≠bridas: **vectoriales** (por similitud sem√°ntica) y **filtradas** (por condiciones estructuradas). Es ideal para aplicaciones como:

- RAG (Retrieval-Augmented Generation)
- Recomendadores
- Motores de b√∫squeda sem√°ntica
- Chatbots con contexto vectorial

#### **Caracter√≠sticas Principales**

- Soporte de vectores de alta dimensi√≥n:
- B√∫squeda aproximada y exacta (HNSW, Brute Force)
- Filtros por metadatos estructurados
- Indexaci√≥n incremental y tiempo real
- Optimizado para CPU y disponible con soporte para GPU
- Integraci√≥n con FastEmbed y frameworks de ML/IA
- Soporta m√∫ltiples colecciones y namespaces.
- API REST y gRPC.
- Persistencia en disco o en memoria.

#### **Arquitectura**

![alt text](./img/image.png)

- Motor de b√∫squeda HNSW (Hierarchical Navigable Small World): estructura de grafo eficiente para b√∫squedas vectoriales aproximadas.
- Gesti√≥n de Payloads: cada vector puede tener metadatos adjuntos para filtrado sem√°ntico estructurado.
- Shard Manager: cuando se usa en cl√∫ster, balancea y distribuye datos entre nodos.

#### **Almacenamiento de Datos: Colecciones y Puntos**

Qdrant organiza los datos en **colecciones**, similares a las tablas en una base de datos relacional. Cada colecci√≥n agrupa un conjunto de vectores y su informaci√≥n asociada.

![alt text](./img/image_2.png)

*Colecci√≥n*

Una colecci√≥n representa un espacio de b√∫squeda aislado con su propio √≠ndice, configuraci√≥n y datos. Puedes tener m√∫ltiples colecciones, por ejemplo: `faq_articles`, `legal_docs` y `product_catalog`

Cada colecci√≥n define:

- El tama√±o de los vectores (dimensionalidad)
- La m√©trica de similitud (`Cosine`, `Euclidean`, `Dot`)
- Opcionalmente, si usa HNSW u otro tipo de indexado

*Punto*

Los datos dentro de una colecci√≥n se almacenan como puntos (PointStruct). Cada punto es un objeto que representa un vector en el espacio sem√°ntico y contiene:
- `id`: identificador √∫nico del punto (entero o UUID)
- `vector`: array de floats (el embedding)
- `payload`: diccionario de metadatos JSON asociados al vector

Este dise√±o permite, realizar b√∫squedas vectoriales por similitud sobre `vector` y filtrar por metadatos estructurados contenidos en `payload`

Los `puntos` se pueden insertar individualmente o por lotes (`batch upsert`) usando la API o el cliente oficial (`qdrant-client` para Python).

*Indexaci√≥n*

Una vez insertados, los puntos pueden ser indexados autom√°ticamente por el motor HNSW (si est√° habilitado) o buscados mediante fuerza bruta (Brute Force) si no hay √≠ndice disponible. Los √≠ndices permiten acelerar la b√∫squeda de vectores similares sin recorrer todos los datos.

#### **Funcionalidades Clave**

- `search`: buscar por similitud vectorial.
- `recommend`: sugerencias basadas en vectores positivos y negativos.
- `scroll`: recuperaci√≥n paginada.
- `filter`: b√∫squedas filtradas por metadatos (ej. categor√≠a, fecha).
- `payload`: adjuntar informaci√≥n extra (JSON) a los vectores.
- `update/delete`: modificaciones en tiempo real.
- `collections`: m√∫ltiples espacios de trabajo aislados.
- `snapshots/backups`: gesti√≥n de respaldo y restauraci√≥n.

#### **Seguridad**

- Autenticaci√≥n basada en tokens (a partir de la versi√≥n 1.5).
- Control de acceso a endpoints v√≠a configuraci√≥n de API keys.
- Comunicaciones seguras mediante TLS (cuando se usa proxy o configuraci√≥n externa).
- Integrable con firewalls, proxies y servicios de autenticaci√≥n externos.

#### **Alta Disponibilidad y Redundancia**

- Modo Cl√∫ster (Enterprise o Community):
    - Distribuci√≥n horizontal de shards en m√∫ltiples nodos.
    - Replicaci√≥n de shards para tolerancia a fallos.
    - Rebalanceo autom√°tico ante cambios de topolog√≠a.
- Backups y snapshots peri√≥dicos para recuperaci√≥n de desastres.
- Qdrant Cloud ofrece despliegue gestionado con SLA, HA y escalado autom√°tico.

#### **Tipos de B√∫squeda en Qdrant**

Qdrant permite realizar b√∫squedas inteligentes sobre contenido no estructurado como texto, im√°genes o audio. A trav√©s de incrustaciones (embeddings), Qdrant transforma los datos en vectores sem√°nticos y permite realizar distintos tipos de b√∫squeda adaptados al caso de uso.

A continuaci√≥n, se explican los enfoques m√°s comunes:

#### 1. B√∫squeda Sem√°ntica (Semantic Search)

**¬øQu√© es?**

La b√∫squeda sem√°ntica recupera informaci√≥n basada en **el significado** de los datos, en lugar de buscar coincidencias exactas de palabras.

**¬øC√≥mo funciona?**

- Se convierte la consulta del usuario en un vector utilizando el mismo modelo de incrustaci√≥n que se us√≥ para indexar los documentos.
- Se calcula la **similitud** entre este vector de consulta y los vectores ya almacenados en Qdrant (usualmente mediante **similitud de coseno**).
- Se devuelven los documentos cuyos vectores est√°n m√°s cercanos en el espacio sem√°ntico.

**¬øCu√°ndo usarla?**

- Cuando es importante recuperar resultados que expresen **la misma idea aunque usen palabras distintas**.
- Casos como: FAQ, sistemas RAG, recuperaci√≥n de contexto para LLMs, motores de b√∫squeda inteligentes.

#### 2. B√∫squeda Exacta (Exact Match Search)

**¬øQu√© es?**

Es una b√∫squeda basada en **coincidencias exactas** de valores en campos estructurados (metadatos), similar a filtros SQL.

**¬øC√≥mo funciona?**

- No utiliza vectores ni similitud sem√°ntica.
- Se realiza un filtrado directo por valores espec√≠ficos en el payload (metadatos) de los documentos.
- Ejemplo: `idioma = "es"` o `categoria = "legal"`.

**¬øCu√°ndo usarla?**

- Para filtrar por propiedades exactas antes de una b√∫squeda sem√°ntica.
- En sistemas donde ciertos criterios (fecha, idioma, tipo, etc.) son obligatorios.
- Tambi√©n se puede usar sola, cuando no se requiere inferencia sem√°ntica.

**Ventajas**

- Muy eficiente y determinista. Se comporta como una base de datos estructurada tradicional.

#### 3. B√∫squeda Exacta con BM25 (BM25 Sparse Text Search)

**¬øQu√© es?**

Es una t√©cnica de recuperaci√≥n de informaci√≥n basada en el modelo estad√≠stico **BM25**, el cual calcula la relevancia de los documentos respecto a una consulta textual exacta. Utiliza vectores **dispersos** que representan la presencia y frecuencia de palabras, sin aplicar modelos de lenguaje ni embeddings sem√°nticos.

**¬øC√≥mo funciona?**

- Se tokenizan los textos (documentos y consulta) y se construyen vectores dispersos usando TF-IDF o BM25.
- BM25 eval√∫a la relevancia en funci√≥n de:
  - Frecuencia de cada t√©rmino en el documento (TF).
  - Qu√© tan informativo es el t√©rmino en el corpus (IDF).
  - Longitud del documento (penaliza documentos muy largos).
- Los documentos se ordenan por su **puntuaci√≥n BM25** y se devuelven los m√°s relevantes.

**Ventajas**

- Requiere pocos recursos (no necesita modelos preentrenados).
- Captura con precisi√≥n los t√©rminos **literalmente coincidentes** que son significativos.
- Es **r√°pida y eficaz** para textos cortos o consultas espec√≠ficas.

**Limitaciones**

- No reconoce sin√≥nimos, intenciones ni contexto sem√°ntico.
- Es sensible a errores ortogr√°ficos y variaciones de redacci√≥n.
- Requiere un buen preprocesamiento textual (idioma, stopwords, etc.).

**Casos de uso**

- Consultas con **palabras clave t√©cnicas o exactas** (ej. errores, productos, cl√°usulas legales).
- Documentaci√≥n donde el lenguaje exacto es importante (ej. bases de conocimiento).
- Complemento a b√∫squedas sem√°nticas en esquemas h√≠bridos (textual + vectorial).

#### 4. B√∫squeda Multi-Stage (Multi-stage Search)

**¬øQu√© es?**

Es una t√©cnica en la que se encadenan varias etapas de b√∫squeda o filtrado para **refinar progresivamente** los resultados.

**¬øC√≥mo funciona?**

1. **Etapa 1**: Se aplica una b√∫squeda o filtro inicial (por ejemplo, una b√∫squeda exacta o un filtro por metadatos).
2. **Etapa 2**: Sobre los resultados obtenidos, se realiza una b√∫squeda vectorial m√°s precisa o costosa.
3. **Opcionalmente**, se puede agregar una tercera etapa con re-ranking (reordenamiento por alg√∫n criterio adicional).

**¬øCu√°ndo usarla?**

- Cuando el volumen de datos es grande y se quiere **acotar primero** por criterios estructurados.
- Cuando se necesita una **combinaci√≥n jer√°rquica de criterios**, como idioma ‚Üí categor√≠a ‚Üí sem√°ntica.

**Ventajas**

- Reduce el costo computacional de comparar todos los vectores.
- Permite una b√∫squeda escalable y precisa.

#### 5. B√∫squeda H√≠brida (Hybrid Search)

**¬øQu√© es?**

Combina **b√∫squeda exacta basada en texto** (BM25, keyword matching) con **b√∫squeda vectorial sem√°ntica**, devolviendo un resultado mixto ordenado por relevancia total.

**¬øC√≥mo funciona?**

- Se ejecutan en paralelo una b√∫squeda textual exacta y una b√∫squeda sem√°ntica.
- Se combinan ambas puntuaciones (por ejemplo, con pesos personalizados) para determinar el ranking final de resultados.

**¬øCu√°ndo usarla?**

- Cuando los usuarios mezclan **palabras clave t√©cnicas y lenguaje natural**.
- En casos donde se requiere precisi√≥n con t√©rminos espec√≠ficos (ej. c√≥digos de error, identificadores).

**Ejemplo:**

Buscar ‚Äú¬øc√≥mo funciona la cl√°usula penal 101-B?‚Äù puede beneficiarse de:
- Coincidencia exacta con ‚Äú101-B‚Äù (keyword)
- B√∫squeda sem√°ntica sobre ‚Äúc√≥mo funciona la cl√°usula penal‚Äù

#### 6.Otros tipos de b√∫squeda (avanzados)

Qdrant tambi√©n permite, directamente o mediante integraci√≥n, implementar b√∫squedas m√°s avanzadas:

- **B√∫squeda personalizada por usuario** (personalizaci√≥n mediante vectores contextuales).
- **B√∫squeda con feedback negativo/positivo** (ej. ‚Äúparecido a A, pero no como B‚Äù).
- **Re-ranking basado en LLMs** (aplicar un modelo adicional para reordenar).
- **B√∫squeda multimodal** (comparar texto con im√°genes, audio, etc.).
- **B√∫squeda por distancia geogr√°fica combinada con sem√°ntica** (geo + vectores).

Estos enfoques son ideales para sistemas de recomendaci√≥n, motores de b√∫squeda h√≠bridos complejos o entornos de producci√≥n avanzados.


## üõ†Ô∏è Ejemplo pr√°ctico de Qdrant

### Creaci√≥n de un entorno de desarrollo

Para crear y gestionar el entorno de Python de este proyecto se utiliza `uv`, una herramienta moderna que combina la gesti√≥n de entornos virtuales y la resoluci√≥n de dependencias de forma r√°pida y eficiente.

Este enfoque reemplaza el uso tradicional de herramientas como `venv`, `pip` y `virtualenv`, ofreciendo una experiencia m√°s simple y √°gil.

‚ÑπÔ∏è Para m√°s detalles sobre c√≥mo instalar y utilizar uv, consulta el archivo [`working-with-uv.md`](../docs/working-with-uv.md)

Una vez instalado `uv`, puedes crear el entorno virtual e instalar todas las dependencias necesarias con un solo comando:

```bash
uv venv && uv sync
```

Este comando crear√° un entorno virtual en el directorio del proyecto y sincronizar√° las librer√≠as especificadas en el archivo `pyproject.toml`.

### Interactuando con Qdrant usando Python

#### **1. Descargar la imagen de Qdrant desde Docker Hub**

```bash
docker pull qdrant/qdrant
```

#### **2. Ejecutar el servicio**

```bash
docker run -p 6333:6333 -p 6334:6334 \
    -v "$(pwd)/qdrant_storage:/qdrant/storage:z" \
    qdrant/qdrant
```

Con esta configuraci√≥n predeterminada, todos los datos se almacenar√°n en el directorio  `./qdrant_storage`, el cual ser√° accesible tanto para el contenedor como para el host.

Qdrant ahora estar√° disponible en:
- API REST: http://localhost:6333
- Interfaz web: http://localhost:6333/dashboard
- API gRPC: http://localhost:6334

#### **3. Flujo b√°sico**

Si deseas ver un ejemplo pr√°ctico de c√≥mo crear una colecci√≥n, agregar elementos y realizar una consulta, puedes consultar el archivo [`0_quickstart`](./notebook/0_quickstart.ipynb).

Este notebook incluye ejemplos de:
- Creaci√≥n de un cliente.
- Creaci√≥n de una colecci√≥n.
- Inserci√≥n de puntos/vectores en una colecci√≥n.
- Recuperaci√≥n de los puntos/vectores m√°s cercanos.
- Aplicaci√≥n de filtros en las b√∫squedas.

#### **4. Generaci√≥n de incrustaciones (embeddings) con FastEmbed**

Si deseas ver un ejemplo pr√°ctico de c√≥mo generar incrustaciones de texto utilizando la librer√≠a `FastEmbed`, puedes consultar el archivo [`1_fastembed_embeddings`](./notebook/1_fastembed_embeddings.ipynb).

Este notebook incluye ejemplos de:
- Instalaci√≥n y carga del modelo de incrustaci√≥n (`BAAI/bge-small-en-v1.5`, entre otros).
- Transformaci√≥n de textos en vectores num√©ricos (embeddings).
- Visualizaci√≥n de las incrustaciones generadas.
- Preparaci√≥n de los vectores para su posterior indexaci√≥n en una colecci√≥n de Qdrant.

#### **5. B√∫squeda sem√°ntica con Qdrant**

Si deseas ver un ejemplo pr√°ctico de c√≥mo realizar una b√∫squeda sem√°ntica utilizando Qdrant, puedes consultar el archivo [`2_sematic_search.ipynb`](./notebook/2_sematic_search.ipynb).

Este notebook incluye ejemplos de:
- Creaci√≥n de una colecci√≥n en Qdrant para b√∫squeda sem√°ntica.
- Inserci√≥n de vectores densos generados previamente.
- Ejecuci√≥n de b√∫squedas basadas en similitud sem√°ntica.
- Interpretaci√≥n de los resultados obtenidos en consultas de lenguaje natural.

#### **6. Construcci√≥n de un sistema RAG con Qdrant**

Si deseas ver c√≥mo construir un sistema RAG (Retrieval-Augmented Generation) b√°sico, puedes consultar el archivo [`3_rag_and_qdrant.ipynb`](./notebook/3_rag_and_qdrant.ipynb).

Este notebook incluye ejemplos de:
- Indexaci√≥n de documentos con metadatos relevantes.
- Implementaci√≥n de un flujo de recuperaci√≥n y generaci√≥n con OpenAI.
- Uso de Qdrant como backend para la recuperaci√≥n sem√°ntica.
- Generaci√≥n de respuestas fundamentadas en los documentos cargados.


#### **7. B√∫squeda h√≠brida: combinaci√≥n de vectores densos y dispersos**

Si deseas ver c√≥mo realizar una b√∫squeda h√≠brida combinando embeddings densos y vectores dispersos (como BM25), puedes consultar el archivo [`4_hybrid_search.ipynb`](./notebook/4_hybrid_search.ipynb).

Este notebook incluye ejemplos de:
- Configuraci√≥n de una colecci√≥n h√≠brida en Qdrant.
- Inserci√≥n de puntos con vectores densos y texto para vectorizaci√≥n dispersa.
- Ejecuci√≥n de b√∫squedas h√≠bridas con fusi√≥n de puntuaciones.
- Comparaci√≥n entre resultados sem√°nticos, l√©xicos e h√≠bridos.


## üîó Lectura recomendada
Recomendado para profundizar en los conceptos clave y ampliar tu comprensi√≥n
* [What is Qdrant?](https://qdrant.tech/documentation/overview/)
* [How Does Vector Search Work in Qdrant?](https://qdrant.tech/documentation/overview/vector-search/)
* [How to Get Started with Qdrant Locally](https://qdrant.tech/documentation/quickstart/)
* [Built for Vector Search](https://qdrant.tech/articles/dedicated-vector-search/)
* [Qdrant Web UI](https://qdrant.tech/documentation/web-ui/)
* [How to Generate Text Embedings with FastEmbed](https://qdrant.tech/documentation/fastembed/fastembed-quickstart/)
* [Using FastEmbed with Qdrant for Vector Search](https://qdrant.tech/documentation/fastembed/fastembed-semantic-search/)
* [Qdrant - Concepts](https://qdrant.tech/documentation/concepts/)
* [An Introduction to Vector Databases](https://qdrant.tech/articles/what-is-a-vector-database/)
* [Build Your First Semantic Search Engine](https://qdrant.tech/documentation/beginner-tutorials/search-beginners/)
* [A Complete Guide to Filtering in Vector Search](https://qdrant.tech/articles/vector-search-filtering/)
* [Hybrid Search Revamped - Building with Qdrant's Query API](https://qdrant.tech/articles/hybrid-search/)
* [Estrellas en el cielo sem√°ntico: b√∫squeda vectorial con Qdrant](https://medium.com/@j92riquelme/estrellas-en-el-cielo-sem√°ntico-b√∫squeda-vectorial-con-qdrant-89072b49f418)
* [B√∫squeda vectorial: organizaci√≥n de datos, modelos de incrustaci√≥n y similitud sem√°ntica](https://medium.com/@j92riquelme/b√∫squeda-vectorial-organizaci√≥n-de-datos-modelos-de-incrustaci√≥n-y-similitud-sem√°ntica-75954ec9b6aa)
* [Mapeando el Universo Sem√°ntico con Qdrant: De Vectores a Visualizaci√≥n](https://medium.com/@j92riquelme/mapeando-el-universo-sem√°ntico-con-qdrant-de-vectores-a-visualizaci√≥n-9dcfa078a21a)
* [Navegando el Espacio Sem√°ntico: Una Gu√≠a T√©cnica para B√∫squedas de Similitud y Filtrado con Qdrant](https://medium.com/@j92riquelme/navegando-el-espacio-sem√°ntico-una-gu√≠a-t√©cnica-para-b√∫squedas-de-similitud-y-filtrado-con-qdrant-75d1b82cc1e2)
* [Dominando la B√∫squeda H√≠brida: Una Gu√≠a T√©cnica Profunda sobre Qdrant, Vectores Dispersos y Fusi√≥n de Relevancia](https://medium.com/@j92riquelme/dominando-la-busqueda-hibrida-qdrant-vectores-dispersos-y-fusion-f8e82d5afb06)
* [Construyendo un Sistema RAG con Qdrant](https://medium.com/@j92riquelme/construyendo-un-sistema-rag-con-qdrant-a551390b8f30)
* [Del RAG cl√°sico a la b√∫squeda h√≠brida con Qdrant](https://medium.com/@j92riquelme/del-rag-clasico-a-la-busqueda-hibrida-con-qdrant-5b8f67a39e86)

## ‚ñ∂Ô∏è Videos recomendados
Selecci√≥n de videos para reforzar visualmente los temas abordados
* [What is RAG? Building Better LLM Systems with Qdrant](https://www.youtube.com/watch?v=rtIyQPJUd_U)
* [How Vector Search Algorithms Work: An Intro to Qdrant](https://www.youtube.com/watch?v=mXNrhyw4q84)
* [Exploring Qdrant concepts - Collections](https://www.youtube.com/watch?v=0sg7pJo0siU)
* [Qdrant Tutorial - Semantic Search for Beginners](https://www.youtube.com/watch?v=AASiqmtKo54)
* [Getting Started with Qdrant](https://youtu.be/LRcZ9pbGnno?si=0xPf3C9oGpR6BxRz)
* [Chatbot with RAG, using LangChain, OpenAI, and Groq](https://www.youtube.com/watch?v=O60-KuZZeQA)
* [Music Recommendation System with Qdrant Vector Search and Audio Embeddings](https://www.youtube.com/watch?v=id5ql-Abq4Y)
* [How to Build the Ultimate Hybrid Search with Qdrant](https://www.youtube.com/watch?v=LAZOxqzceEU)


## üìö Cursos adicionales recomendados
Recursos complementarios para seguir aprendiendo y fortaleciendo tus habilidades.

* [Retrieval Optimization: From Tokenization to Vector Quantization](https://www.deeplearning.ai/short-courses/retrieval-optimization-from-tokenization-to-vector-quantization/?utm_campaign=qdrant-launch&utm_medium=qdrant&utm_source=partner-promo)

---

> üìå **Nota:** este repositorio complementa el curso **LLM Zoomcamp** de [DataTalks.Club](https://datatalks.club/), y contiene notas, lecturas, videos, ejemplos y recursos adicionales.  
> Para acceder al contenido oficial del curso, visita el [**repositorio principal en GitHub**](https://github.com/DataTalksClub/llm-zoomcamp).
