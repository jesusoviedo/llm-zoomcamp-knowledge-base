# Semana 2 - LLM Zoomcamp

Este documento recopila mis apuntes y recursos para la **Semana 2** del curso LLM Zoomcamp.

## ðŸ“ Notas de la teorÃ­a

### Busqueda Vectorial

La bÃºsqueda vectorial permite encontrar objetos similares transformÃ¡ndolos en vectores de alta dimensiÃ³n y comparÃ¡ndolos en funciÃ³n de su cercanÃ­a en ese espacio. Qdrant es una base de datos openâ€‘source escrita en Rust, diseÃ±ada para realizar esa bÃºsqueda de manera rÃ¡pida y escalable

**Vectores**

En aprendizaje automÃ¡tico, un vector es una representaciÃ³n numÃ©rica de un objeto complejo (texto, imagen, usuario, etc.) en un espacio multidimensional. Si imaginas cada dato como una canciÃ³n, el vector serÃ­a la partitura que resume su melodÃ­a semÃ¡ntica.

**MÃ©tricas de similitud**

Comparar vectores es medir distancias:
- Similitud del coseno: compara la orientaciÃ³n de dos vectores (Ã¡ngulo).
- Distancia Euclidiana: mide la distancia â€œdirectaâ€ en el espacio.
- Producto escalar: correlaciona vectores en funciÃ³n de su producto escalar.

**BÃºsqueda semÃ¡ntica y disimilitud**

- BÃºsqueda de similitud semÃ¡ntica: encuentra vectores cercanos al vector de consulta, como buscar estrellas de la misma constelaciÃ³n.
- BÃºsqueda por disimilitud: selecciona vectores lejanos, Ãºtil para detecciÃ³n de anomalÃ­as.

**BÃºsqueda de diversidad**

Algunos casos requieren variedad. Una manera serÃ­a filtrar resultados muy cercanos entre sÃ­ (â€œvecinos ruidososâ€), garantizando que los resultados sean semÃ¡nticamente distintos entre sÃ­.


**Recomendaciones basadas en vectores**
* Recomendaciones de caracterÃ­sticas vectoriales: almacenamos vectores de usuarios y productos. Luego, al comparar vectores similares, sugerimos Ã­tems que estÃ¡n cerca en ese espacio.

* Recomendaciones de distancia relativa: no se trata solo de encontrar los mÃ¡s similares, sino de medir "lo suficientemente cerca" respecto al promedio, usando filtros dinÃ¡micos y normalizaciÃ³n dentro del espacio vectorial.

**Descubrimiento**

Encuentros inesperados son posibles gracias a la diversidad vectorial: descubrir relaciones no evidentes entre documentos, temas o productos.

### Qdrant: Motor de BÃºsqueda Vectorial SemÃ¡ntica

Qdrant (Quadrant) es un **motor de base de datos vectorial de alto rendimiento** diseÃ±ado para bÃºsquedas semÃ¡nticas, recuperaciÃ³n de informaciÃ³n por similitud y aplicaciones de inteligencia artificial. EstÃ¡ optimizado para manejar **incrustaciones vectoriales** generadas por modelos de machine learning y proporciona una API eficiente para realizar bÃºsquedas de vecinos mÃ¡s cercanos (k-NN) de manera precisa, rÃ¡pida y escalable.

Qdrant permite almacenar vectores densos (embeddings) junto con **metadatos** estructurados, habilitando bÃºsquedas hÃ­bridas: **vectoriales** (por similitud semÃ¡ntica) y **filtradas** (por condiciones estructuradas). Es ideal para aplicaciones como:

- RAG (Retrieval-Augmented Generation)
- Recomendadores
- Motores de bÃºsqueda semÃ¡ntica
- Chatbots con contexto vectorial

#### **CaracterÃ­sticas Principales**

- Soporte de vectores de alta dimensiÃ³n:
- BÃºsqueda aproximada y exacta (HNSW, Brute Force)
- Filtros por metadatos estructurados
- IndexaciÃ³n incremental y tiempo real
- Optimizado para CPU y disponible con soporte para GPU
- IntegraciÃ³n con FastEmbed y frameworks de ML/IA
- Soporta mÃºltiples colecciones y namespaces.
- API REST y gRPC.
- Persistencia en disco o en memoria.

#### **Arquitectura**

![alt text](./img/image.png)

- Motor de bÃºsqueda HNSW (Hierarchical Navigable Small World): estructura de grafo eficiente para bÃºsquedas vectoriales aproximadas.
- GestiÃ³n de Payloads: cada vector puede tener metadatos adjuntos para filtrado semÃ¡ntico estructurado.
- Shard Manager: cuando se usa en clÃºster, balancea y distribuye datos entre nodos.

#### **Almacenamiento de Datos: Colecciones y Puntos**

Qdrant organiza los datos en **colecciones**, similares a las tablas en una base de datos relacional. Cada colecciÃ³n agrupa un conjunto de vectores y su informaciÃ³n asociada.

![alt text](./img/image_2.png)

*ColecciÃ³n*

Una colecciÃ³n representa un espacio de bÃºsqueda aislado con su propio Ã­ndice, configuraciÃ³n y datos. Puedes tener mÃºltiples colecciones, por ejemplo: `faq_articles`, `legal_docs` y `product_catalog`

Cada colecciÃ³n define:

- El tamaÃ±o de los vectores (dimensionalidad)
- La mÃ©trica de similitud (`Cosine`, `Euclidean`, `Dot`)
- Opcionalmente, si usa HNSW u otro tipo de indexado

*Punto*

Los datos dentro de una colecciÃ³n se almacenan como puntos (PointStruct). Cada punto es un objeto que representa un vector en el espacio semÃ¡ntico y contiene:
- `id`: identificador Ãºnico del punto (entero o UUID)
- `vector`: array de floats (el embedding)
- `payload`: diccionario de metadatos JSON asociados al vector

Este diseÃ±o permite, realizar bÃºsquedas vectoriales por similitud sobre `vector` y filtrar por metadatos estructurados contenidos en `payload`

Los `puntos` se pueden insertar individualmente o por lotes (`batch upsert`) usando la API o el cliente oficial (`qdrant-client` para Python).

*IndexaciÃ³n*

Una vez insertados, los puntos pueden ser indexados automÃ¡ticamente por el motor HNSW (si estÃ¡ habilitado) o buscados mediante fuerza bruta (Brute Force) si no hay Ã­ndice disponible. Los Ã­ndices permiten acelerar la bÃºsqueda de vectores similares sin recorrer todos los datos.

#### **Funcionalidades Clave**

- `search`: buscar por similitud vectorial.
- `recommend`: sugerencias basadas en vectores positivos y negativos.
- `scroll`: recuperaciÃ³n paginada.
- `filter`: bÃºsquedas filtradas por metadatos (ej. categorÃ­a, fecha).
- `payload`: adjuntar informaciÃ³n extra (JSON) a los vectores.
- `update/delete`: modificaciones en tiempo real.
- `collections`: mÃºltiples espacios de trabajo aislados.
- `snapshots/backups`: gestiÃ³n de respaldo y restauraciÃ³n.

#### **Seguridad**

- AutenticaciÃ³n basada en tokens (a partir de la versiÃ³n 1.5).
- Control de acceso a endpoints vÃ­a configuraciÃ³n de API keys.
- Comunicaciones seguras mediante TLS (cuando se usa proxy o configuraciÃ³n externa).
- Integrable con firewalls, proxies y servicios de autenticaciÃ³n externos.

#### **Alta Disponibilidad y Redundancia**

- Modo ClÃºster (Enterprise o Community):
    - DistribuciÃ³n horizontal de shards en mÃºltiples nodos.
    - ReplicaciÃ³n de shards para tolerancia a fallos.
    - Rebalanceo automÃ¡tico ante cambios de topologÃ­a.
- Backups y snapshots periÃ³dicos para recuperaciÃ³n de desastres.
- Qdrant Cloud ofrece despliegue gestionado con SLA, HA y escalado automÃ¡tico.

#### **Tipos de BÃºsqueda en Qdrant**

Qdrant permite realizar bÃºsquedas inteligentes sobre contenido no estructurado como texto, imÃ¡genes o audio. A travÃ©s de incrustaciones (embeddings), Qdrant transforma los datos en vectores semÃ¡nticos y permite realizar distintos tipos de bÃºsqueda adaptados al caso de uso.

A continuaciÃ³n, se explican los enfoques mÃ¡s comunes:

#### 1. BÃºsqueda SemÃ¡ntica (Semantic Search)

**Â¿QuÃ© es?**

La bÃºsqueda semÃ¡ntica recupera informaciÃ³n basada en **el significado** de los datos, en lugar de buscar coincidencias exactas de palabras.

**Â¿CÃ³mo funciona?**

- Se convierte la consulta del usuario en un vector utilizando el mismo modelo de incrustaciÃ³n que se usÃ³ para indexar los documentos.
- Se calcula la **similitud** entre este vector de consulta y los vectores ya almacenados en Qdrant (usualmente mediante **similitud de coseno**).
- Se devuelven los documentos cuyos vectores estÃ¡n mÃ¡s cercanos en el espacio semÃ¡ntico.

**Â¿CuÃ¡ndo usarla?**

- Cuando es importante recuperar resultados que expresen **la misma idea aunque usen palabras distintas**.
- Casos como: FAQ, sistemas RAG, recuperaciÃ³n de contexto para LLMs, motores de bÃºsqueda inteligentes.

#### 2. BÃºsqueda Exacta (Exact Match Search)

**Â¿QuÃ© es?**

Es una bÃºsqueda basada en **coincidencias exactas** de valores en campos estructurados (metadatos), similar a filtros SQL.

**Â¿CÃ³mo funciona?**

- No utiliza vectores ni similitud semÃ¡ntica.
- Se realiza un filtrado directo por valores especÃ­ficos en el payload (metadatos) de los documentos.
- Ejemplo: `idioma = "es"` o `categoria = "legal"`.

**Â¿CuÃ¡ndo usarla?**

- Para filtrar por propiedades exactas antes de una bÃºsqueda semÃ¡ntica.
- En sistemas donde ciertos criterios (fecha, idioma, tipo, etc.) son obligatorios.
- TambiÃ©n se puede usar sola, cuando no se requiere inferencia semÃ¡ntica.

**Ventajas**

- Muy eficiente y determinista. Se comporta como una base de datos estructurada tradicional.

#### 3. BÃºsqueda Exacta con BM25 (BM25 Sparse Text Search)

**Â¿QuÃ© es?**

Es una tÃ©cnica de recuperaciÃ³n de informaciÃ³n basada en el modelo estadÃ­stico **BM25**, el cual calcula la relevancia de los documentos respecto a una consulta textual exacta. Utiliza vectores **dispersos** que representan la presencia y frecuencia de palabras, sin aplicar modelos de lenguaje ni embeddings semÃ¡nticos.

**Â¿CÃ³mo funciona?**

- Se tokenizan los textos (documentos y consulta) y se construyen vectores dispersos usando TF-IDF o BM25.
- BM25 evalÃºa la relevancia en funciÃ³n de:
  - Frecuencia de cada tÃ©rmino en el documento (TF).
  - QuÃ© tan informativo es el tÃ©rmino en el corpus (IDF).
  - Longitud del documento (penaliza documentos muy largos).
- Los documentos se ordenan por su **puntuaciÃ³n BM25** y se devuelven los mÃ¡s relevantes.

**Ventajas**

- Requiere pocos recursos (no necesita modelos preentrenados).
- Captura con precisiÃ³n los tÃ©rminos **literalmente coincidentes** que son significativos.
- Es **rÃ¡pida y eficaz** para textos cortos o consultas especÃ­ficas.

**Limitaciones**

- No reconoce sinÃ³nimos, intenciones ni contexto semÃ¡ntico.
- Es sensible a errores ortogrÃ¡ficos y variaciones de redacciÃ³n.
- Requiere un buen preprocesamiento textual (idioma, stopwords, etc.).

**Casos de uso**

- Consultas con **palabras clave tÃ©cnicas o exactas** (ej. errores, productos, clÃ¡usulas legales).
- DocumentaciÃ³n donde el lenguaje exacto es importante (ej. bases de conocimiento).
- Complemento a bÃºsquedas semÃ¡nticas en esquemas hÃ­bridos (textual + vectorial).

#### 4. BÃºsqueda Multi-Stage (Multi-stage Search)

**Â¿QuÃ© es?**

Es una tÃ©cnica en la que se encadenan varias etapas de bÃºsqueda o filtrado para **refinar progresivamente** los resultados.

**Â¿CÃ³mo funciona?**

1. **Etapa 1**: Se aplica una bÃºsqueda o filtro inicial (por ejemplo, una bÃºsqueda exacta o un filtro por metadatos).
2. **Etapa 2**: Sobre los resultados obtenidos, se realiza una bÃºsqueda vectorial mÃ¡s precisa o costosa.
3. **Opcionalmente**, se puede agregar una tercera etapa con re-ranking (reordenamiento por algÃºn criterio adicional).

**Â¿CuÃ¡ndo usarla?**

- Cuando el volumen de datos es grande y se quiere **acotar primero** por criterios estructurados.
- Cuando se necesita una **combinaciÃ³n jerÃ¡rquica de criterios**, como idioma â†’ categorÃ­a â†’ semÃ¡ntica.

**Ventajas**

- Reduce el costo computacional de comparar todos los vectores.
- Permite una bÃºsqueda escalable y precisa.

#### 5. BÃºsqueda HÃ­brida (Hybrid Search)

**Â¿QuÃ© es?**

Combina **bÃºsqueda exacta basada en texto** (BM25, keyword matching) con **bÃºsqueda vectorial semÃ¡ntica**, devolviendo un resultado mixto ordenado por relevancia total.

**Â¿CÃ³mo funciona?**

- Se ejecutan en paralelo una bÃºsqueda textual exacta y una bÃºsqueda semÃ¡ntica.
- Se combinan ambas puntuaciones (por ejemplo, con pesos personalizados) para determinar el ranking final de resultados.

**Â¿CuÃ¡ndo usarla?**

- Cuando los usuarios mezclan **palabras clave tÃ©cnicas y lenguaje natural**.
- En casos donde se requiere precisiÃ³n con tÃ©rminos especÃ­ficos (ej. cÃ³digos de error, identificadores).

**Ejemplo:**

Buscar â€œÂ¿cÃ³mo funciona la clÃ¡usula penal 101-B?â€ puede beneficiarse de:
- Coincidencia exacta con â€œ101-Bâ€ (keyword)
- BÃºsqueda semÃ¡ntica sobre â€œcÃ³mo funciona la clÃ¡usula penalâ€

#### 6.Otros tipos de bÃºsqueda (avanzados)

Qdrant tambiÃ©n permite, directamente o mediante integraciÃ³n, implementar bÃºsquedas mÃ¡s avanzadas:

- **BÃºsqueda personalizada por usuario** (personalizaciÃ³n mediante vectores contextuales).
- **BÃºsqueda con feedback negativo/positivo** (ej. â€œparecido a A, pero no como Bâ€).
- **Re-ranking basado en LLMs** (aplicar un modelo adicional para reordenar).
- **BÃºsqueda multimodal** (comparar texto con imÃ¡genes, audio, etc.).
- **BÃºsqueda por distancia geogrÃ¡fica combinada con semÃ¡ntica** (geo + vectores).

Estos enfoques son ideales para sistemas de recomendaciÃ³n, motores de bÃºsqueda hÃ­bridos complejos o entornos de producciÃ³n avanzados.


## ðŸ› ï¸ Ejemplo prÃ¡ctico de Qdrant

### CreaciÃ³n de un entorno de desarrollo

Para crear y gestionar el entorno de Python de este proyecto se utiliza `uv`, una herramienta moderna que combina la gestiÃ³n de entornos virtuales y la resoluciÃ³n de dependencias de forma rÃ¡pida y eficiente.

Este enfoque reemplaza el uso tradicional de herramientas como `venv`, `pip` y `virtualenv`, ofreciendo una experiencia mÃ¡s simple y Ã¡gil.

â„¹ï¸ Para mÃ¡s detalles sobre cÃ³mo instalar y utilizar uv, consulta el archivo [`working-with-uv.md`](../docs/working-with-uv.md)

Una vez instalado `uv`, puedes crear el entorno virtual e instalar todas las dependencias necesarias con un solo comando:

```bash
uv venv && uv sync
```

Este comando crearÃ¡ un entorno virtual en el directorio del proyecto y sincronizarÃ¡ las librerÃ­as especificadas en el archivo `pyproject.toml`.

### Interactuando con Qdrant usando Python

#### **1. Descargar la imagen de Qdrant desde Docker Hub**

```bash
docker pull qdrant/qdrant
```

#### **2. Ejecutar el servicio**

```bash
docker run -p 6333:6333 -p 6334:6334 \
    -v "$(pwd)/qdrant_storage:/qdrant/storage:z" \
    qdrant/qdrant
```

Con esta configuraciÃ³n predeterminada, todos los datos se almacenarÃ¡n en el directorio  `./qdrant_storage`, el cual serÃ¡ accesible tanto para el contenedor como para el host.

Qdrant ahora estarÃ¡ disponible en:
- API REST: http://localhost:6333
- Interfaz web: http://localhost:6333/dashboard
- API gRPC: http://localhost:6334

#### **3. Flujo bÃ¡sico**

Si deseas ver un ejemplo prÃ¡ctico de cÃ³mo crear una colecciÃ³n, agregar elementos y realizar una consulta, puedes consultar el archivo [`0_quickstart`](./notebook/0_quickstart.ipynb).

Este notebook incluye ejemplos de:
- CreaciÃ³n de un cliente.
- CreaciÃ³n de una colecciÃ³n.
- InserciÃ³n de puntos/vectores en una colecciÃ³n.
- RecuperaciÃ³n de los puntos/vectores mÃ¡s cercanos.
- AplicaciÃ³n de filtros en las bÃºsquedas.

#### **4. GeneraciÃ³n de incrustaciones (embeddings) con FastEmbed**

Si deseas ver un ejemplo prÃ¡ctico de cÃ³mo generar incrustaciones de texto utilizando la librerÃ­a `FastEmbed`, puedes consultar el archivo [`1_fastembed_embeddings`](./notebook/1_fastembed_embeddings.ipynb).

Este notebook incluye ejemplos de:
- InstalaciÃ³n y carga del modelo de incrustaciÃ³n (`BAAI/bge-small-en-v1.5`, entre otros).
- TransformaciÃ³n de textos en vectores numÃ©ricos (embeddings).
- VisualizaciÃ³n de las incrustaciones generadas.
- PreparaciÃ³n de los vectores para su posterior indexaciÃ³n en una colecciÃ³n de Qdrant.

#### **5. BÃºsqueda semÃ¡ntica con Qdrant**

Si deseas ver un ejemplo prÃ¡ctico de cÃ³mo realizar una bÃºsqueda semÃ¡ntica utilizando Qdrant, puedes consultar el archivo [`2_sematic_search.ipynb`](./notebook/2_sematic_search.ipynb).

Este notebook incluye ejemplos de:
- CreaciÃ³n de una colecciÃ³n en Qdrant para bÃºsqueda semÃ¡ntica.
- InserciÃ³n de vectores densos generados previamente.
- EjecuciÃ³n de bÃºsquedas basadas en similitud semÃ¡ntica.
- InterpretaciÃ³n de los resultados obtenidos en consultas de lenguaje natural.

#### **6. ConstrucciÃ³n de un sistema RAG con Qdrant**

Si deseas ver cÃ³mo construir un sistema RAG (Retrieval-Augmented Generation) bÃ¡sico, puedes consultar el archivo [`3_rag_and_qdrant.ipynb`](./notebook/3_rag_and_qdrant.ipynb).

Este notebook incluye ejemplos de:
- IndexaciÃ³n de documentos con metadatos relevantes.
- ImplementaciÃ³n de un flujo de recuperaciÃ³n y generaciÃ³n con OpenAI.
- Uso de Qdrant como backend para la recuperaciÃ³n semÃ¡ntica.
- GeneraciÃ³n de respuestas fundamentadas en los documentos cargados.


#### **7. BÃºsqueda hÃ­brida: combinaciÃ³n de vectores densos y dispersos**

Si deseas ver cÃ³mo realizar una bÃºsqueda hÃ­brida combinando embeddings densos y vectores dispersos (como BM25), puedes consultar el archivo [`4_hybrid_search.ipynb`](./notebook/4_hybrid_search.ipynb).

Este notebook incluye ejemplos de:
- ConfiguraciÃ³n de una colecciÃ³n hÃ­brida en Qdrant.
- InserciÃ³n de puntos con vectores densos y texto para vectorizaciÃ³n dispersa.
- EjecuciÃ³n de bÃºsquedas hÃ­bridas con fusiÃ³n de puntuaciones.
- ComparaciÃ³n entre resultados semÃ¡nticos, lÃ©xicos e hÃ­bridos.


## ðŸ”— Lectura recomendada
Recomendado para profundizar en los conceptos clave y ampliar tu comprensiÃ³n
* [What is Qdrant?](https://qdrant.tech/documentation/overview/)
* [How Does Vector Search Work in Qdrant?](https://qdrant.tech/documentation/overview/vector-search/)
* [How to Get Started with Qdrant Locally](https://qdrant.tech/documentation/quickstart/)
* [Built for Vector Search](https://qdrant.tech/articles/dedicated-vector-search/)
* [Qdrant Web UI](https://qdrant.tech/documentation/web-ui/)
* [How to Generate Text Embedings with FastEmbed](https://qdrant.tech/documentation/fastembed/fastembed-quickstart/)
* [Using FastEmbed with Qdrant for Vector Search](https://qdrant.tech/documentation/fastembed/fastembed-semantic-search/)
* [Qdrant - Concepts](https://qdrant.tech/documentation/concepts/)
* [An Introduction to Vector Databases](https://qdrant.tech/articles/what-is-a-vector-database/)
* [Build Your First Semantic Search Engine](https://qdrant.tech/documentation/beginner-tutorials/search-beginners/)
* [A Complete Guide to Filtering in Vector Search](https://qdrant.tech/articles/vector-search-filtering/)
* [Hybrid Search Revamped - Building with Qdrant's Query API](https://qdrant.tech/articles/hybrid-search/)
* [Estrellas en el cielo semÃ¡ntico: bÃºsqueda vectorial con Qdrant](https://medium.com/@j92riquelme/estrellas-en-el-cielo-semÃ¡ntico-bÃºsqueda-vectorial-con-qdrant-89072b49f418)
* [BÃºsqueda vectorial: organizaciÃ³n de datos, modelos de incrustaciÃ³n y similitud semÃ¡ntica](https://medium.com/@j92riquelme/bÃºsqueda-vectorial-organizaciÃ³n-de-datos-modelos-de-incrustaciÃ³n-y-similitud-semÃ¡ntica-75954ec9b6aa)
* [Mapeando el Universo SemÃ¡ntico con Qdrant: De Vectores a VisualizaciÃ³n](https://medium.com/@j92riquelme/mapeando-el-universo-semÃ¡ntico-con-qdrant-de-vectores-a-visualizaciÃ³n-9dcfa078a21a)
* [Navegando el Espacio SemÃ¡ntico: Una GuÃ­a TÃ©cnica para BÃºsquedas de Similitud y Filtrado con Qdrant](https://medium.com/@j92riquelme/navegando-el-espacio-semÃ¡ntico-una-guÃ­a-tÃ©cnica-para-bÃºsquedas-de-similitud-y-filtrado-con-qdrant-75d1b82cc1e2)
* [Dominando la BÃºsqueda HÃ­brida: Una GuÃ­a TÃ©cnica Profunda sobre Qdrant, Vectores Dispersos y FusiÃ³n de Relevancia](https://medium.com/@j92riquelme/dominando-la-busqueda-hibrida-qdrant-vectores-dispersos-y-fusion-f8e82d5afb06)
* [Construyendo un Sistema RAG con Qdrant](https://medium.com/@j92riquelme/construyendo-un-sistema-rag-con-qdrant-a551390b8f30)
* [Del RAG clÃ¡sico a la bÃºsqueda hÃ­brida con Qdrant](https://medium.com/@j92riquelme/del-rag-clasico-a-la-busqueda-hibrida-con-qdrant-5b8f67a39e86)

## â–¶ï¸ Videos recomendados
SelecciÃ³n de videos para reforzar visualmente los temas abordados
* [What is RAG? Building Better LLM Systems with Qdrant](https://www.youtube.com/watch?v=rtIyQPJUd_U)
* [How Vector Search Algorithms Work: An Intro to Qdrant](https://www.youtube.com/watch?v=mXNrhyw4q84)
* [Exploring Qdrant concepts - Collections](https://www.youtube.com/watch?v=0sg7pJo0siU)
* [Qdrant Tutorial - Semantic Search for Beginners](https://www.youtube.com/watch?v=AASiqmtKo54)
* [Getting Started with Qdrant](https://youtu.be/LRcZ9pbGnno?si=0xPf3C9oGpR6BxRz)
* [Chatbot with RAG, using LangChain, OpenAI, and Groq](https://www.youtube.com/watch?v=O60-KuZZeQA)
* [Music Recommendation System with Qdrant Vector Search and Audio Embeddings](https://www.youtube.com/watch?v=id5ql-Abq4Y)
* [How to Build the Ultimate Hybrid Search with Qdrant](https://www.youtube.com/watch?v=LAZOxqzceEU)


## ðŸ“š Cursos adicionales recomendados
Recursos complementarios para seguir aprendiendo y fortaleciendo tus habilidades.

* [Retrieval Optimization: From Tokenization to Vector Quantization](https://www.deeplearning.ai/short-courses/retrieval-optimization-from-tokenization-to-vector-quantization/?utm_campaign=qdrant-launch&utm_medium=qdrant&utm_source=partner-promo)

---

> ðŸ“Œ **Nota:** este repositorio complementa el curso **LLM Zoomcamp** de [DataTalks.Club](https://datatalks.club/), y contiene notas, lecturas, videos, ejemplos y recursos adicionales.  
> Para acceder al contenido oficial del curso, visita el [**repositorio principal en GitHub**](https://github.com/DataTalksClub/llm-zoomcamp).
