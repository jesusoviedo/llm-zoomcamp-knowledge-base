###  **Build Agentic Assistants with OpenAI Function Calling: Part 1**

**Tema:** Creaci贸n de sistemas de Generaci贸n Aumentada por Recuperaci贸n (RAG) m谩s inteligentes y flexibles utilizando un enfoque ag茅ntico y la funcionalidad de "Function Calling" de OpenAI.

**1. Conceptos Fundamentales: RAG B谩sico**

* **驴Qu茅 es RAG (Retrieval Augmented Generation)?**
    * Es un proceso para responder preguntas utilizando una base de conocimiento externa.
    * **Proceso de 3 pasos clave:**
        1. **B煤squeda (Retrieval):** Se busca informaci贸n relevante en una base de datos (ej., FAQ) para encontrar el contexto adecuado.
        2. **Construcci贸n del Prompt:** Se crea una instrucci贸n para el modelo que incluye tanto la pregunta del usuario como el contexto encontrado.
            * **Observaci贸n:** Se recomienda usar etiquetas como `<context>` y `<question>` para estructurar el prompt.
        3. **Generaci贸n de Respuesta (Generation):** Se env铆a el prompt al modelo de lenguaje (LLM), que utiliza el contexto para formular una respuesta precisa.

* **Limitaci贸n Principal del RAG B谩sico:**
    * El sistema solo puede responder si la informaci贸n est谩 en su base de conocimiento. Si se le pregunta algo fuera de su contexto, no podr谩 responder con precisi贸n.

**2. Evoluci贸n: El Enfoque del RAG Ag茅ntico**

* **驴Qu茅 es un RAG Ag茅ntico?**
    * Es una versi贸n m谩s avanzada donde el sistema (el "agente") puede tomar decisiones sobre c贸mo responder.
    * **Decisi贸n clave:** 驴Necesito buscar en la base de datos o puedo responder usando mi conocimiento general?

* **Flujo de trabajo del Agente:**
    1. El usuario hace una pregunta.
    2. El agente analiza la pregunta y decide:
        * **Si es una pregunta general:** Responde directamente.
        * **Si es una pregunta espec铆fica del contexto:** Activa la b煤squeda en la base de conocimiento y luego responde con la informaci贸n encontrada.

* **B煤squeda Ag茅ntica (Agentic Search):**
    * El agente puede realizar m煤ltiples b煤squedas iterativas para explorar un tema a fondo.
    * Si la primera b煤squeda no es suficiente, puede reformular la pregunta y volver a buscar.
    * **Ejemplo pr谩ctico:** Ante la pregunta "驴C贸mo me va bien en el m贸dulo uno?", el agente puede buscar primero "consejos para el m贸dulo uno", luego hacer una b煤squeda m谩s espec铆fica sobre "consejos de estudio para Docker y Terraform".

**3. Implementaci贸n Avanzada: "Function Calling" (Uso de Herramientas)**

* **El Problema:** Crear prompts manuales para cada posible acci贸n (buscar, responder, a帽adir datos) se vuelve complejo y dif铆cil de mantener.

* **La Soluci贸n: "Function Calling"**
    * Es una funcionalidad de APIs como la de OpenAI que permite describirle al modelo las herramientas que tiene disponibles.
    * En vez de l贸gica compleja en el prompt, se le dice al modelo: "Tienes una herramienta para buscar en la FAQ llamada `search`".

    * **Proceso:**
        1. **Definici贸n de Herramientas:** Se define cada funci贸n disponible (`search`, `add_entry`, etc.) con su nombre, descripci贸n y par谩metros requeridos.
        2. **Decisi贸n del Modelo:** El modelo recibe la pregunta del usuario y decide si usar una herramienta y cu谩l.
        3. **Ejecuci贸n:** El c贸digo ejecuta la funci贸n que el modelo solicit贸.
        4. **Retroalimentaci贸n:** El resultado se reenv铆a al modelo para formular la respuesta final.

* **Ventajas Clave:**
    * **Modularidad:** Es f谩cil a帽adir nuevas herramientas sin reescribir los prompts.
    * **Flexibilidad:** Se puede ajustar el comportamiento del agente modificando el prompt del sistema.
    * **Mantenimiento:** Se separa la l贸gica del agente de la definici贸n de sus capacidades, haciendo el c贸digo m谩s limpio.

**Observaciones y Conclusiones de la Clase**

* La elecci贸n entre un RAG simple o ag茅ntico depende del caso de uso. Para una base de conocimiento cerrada, el RAG simple puede ser suficiente.
* El enfoque ag茅ntico con "Function Calling" es muy poderoso para asistentes conversacionales complejos.
* Para entornos en producci贸n, se deben considerar temas como persistencia de datos (ej. uso de Qdrant) y control de entradas inapropiadas (guardrails).

###  **Build Agentic Assistants with OpenAI Function Calling: Part 2**

**1. Introducci贸n y Objetivos del Taller**

* **Continuaci贸n de la Parte 1:** Este taller es la segunda parte, enfocado en profundizar en el concepto de **Llamadas a Funciones (Function Calling)** de OpenAI.
* **Objetivo Principal:** Explicar en detalle la implementaci贸n de las llamadas a funciones, el bucle de ejecuci贸n y la refactorizaci贸n del c贸digo a clases para una mejor organizaci贸n.
* **Recurso Clave:** Se introduce la librer铆a `toy AI kit`, que consolida el c贸digo de los talleres para que sea reutilizable y f谩cil de entender. Se puede instalar v铆a `pip`.

**2. Concepto Clave: 驴Qu茅 es "Function Calling"?**

* **Definici贸n:** Es la capacidad de un modelo de lenguaje (LLM) para decidir de forma aut贸noma si necesita invocar una funci贸n o herramienta externa para responder a una pregunta.
* **Problema que Resuelve:** Un LLM como ChatGPT no tiene conocimiento espec铆fico sobre temas privados o muy recientes (ej. las FAQs de un curso espec铆fico).
* **Soluci贸n:** Se le "ense帽a" al modelo qu茅 herramientas tiene a su disposici贸n.
    * **Implementaci贸n:** Se le proporciona al LLM una **descripci贸n de la funci贸n** (qu茅 hace, qu茅 par谩metros necesita) junto con la pregunta del usuario.
    * **Decisi贸n del Modelo:** Basado en la pregunta, el LLM decide si debe usar la herramienta. Si lo hace, no responde directamente, sino que devuelve una instrucci贸n para llamar a la funci贸n con los argumentos que considera necesarios.

**3. El Bucle de Ejecuci贸n del Agente**

* Este es el "cerebro" del asistente y funciona en dos niveles:
    * **Bucle Exterior (Interacci贸n con el usuario):**
        1. Espera la pregunta del usuario (`input("User: ")`).
        2. Inicia el bucle interior para procesar la pregunta.
        3. Una vez que el bucle interior termina, muestra la respuesta final y espera la siguiente pregunta.
    * **Bucle Interior (Llamadas a funciones):**
        1. Recibe la pregunta y la env铆a al LLM.
        2. **Revisa la respuesta del LLM:**
            * Si el LLM pide llamar a una funci贸n (`function_call`), el c贸digo ejecuta esa funci贸n, recoge el resultado y vuelve a llamar al LLM con esa nueva informaci贸n.
            * Este proceso se repite hasta que el LLM considera que tiene suficiente informaci贸n.
        3. **Fin del Bucle:** Cuando el LLM responde con un mensaje de texto normal (sin pedir m谩s funciones), el bucle interior termina y la respuesta se pasa al usuario.

* **Observaci贸n Importante:** Un LLM puede ser lo suficientemente avanzado como para explicar su razonamiento en texto y, en la misma respuesta, solicitar una llamada a funci贸n.

**4. Refactorizaci贸n y Organizaci贸n del C贸digo (Buenas Pr谩cticas)**

* El c贸digo inicial, aunque funcional, puede volverse desordenado. Se propone una estructura basada en clases para hacerlo m谩s limpio, mantenible y escalable.

* **Clase `Tools`:**
    * **Responsabilidad:** Gestionar todas las herramientas disponibles.
    * Registra las funciones que el agente puede usar.
    * Genera autom谩ticamente las descripciones que necesita la API de OpenAI a partir de los *docstrings* y *type hints* del c贸digo Python (usando la librer铆a `inspect`).

* **Clase `IPythonChatInterface`:**
    * **Responsabilidad:** Manejar todo lo relacionado con la interfaz de usuario (mostrar texto, obtener input, formatear salidas).
    * Utiliza Markdown y HTML para que la conversaci贸n se vea m谩s bonita y ordenada en un notebook, con secciones colapsables (`<details>`) para no saturar la pantalla.

* **Clase `ChatAssistant`:**
    * **Responsabilidad:** Es el orquestador principal. Contiene la l贸gica del bucle de ejecuci贸n y une la interfaz (`IPythonChatInterface`) con las herramientas (`Tools`).

**5. Conclusiones y Pr贸ximos Pasos**

* **Prop贸sito Educativo:** El `toy AI kit` est谩 dise帽ado para aprender los fundamentos. No es para sistemas en producci贸n.
* **Alternativas para Producci贸n:** Para proyectos reales, se recomiendan librer铆as m谩s robustas como `Pydantic AI` o el `OpenAI Agent SDK`, aunque la l贸gica subyacente es muy similar a la vista en el taller.