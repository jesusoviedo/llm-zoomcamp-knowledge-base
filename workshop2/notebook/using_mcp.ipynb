{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8fb41fc-e0c7-4205-92ca-b6f21534f962",
   "metadata": {},
   "source": [
    "## ¿Qué es el Protocolo de Contexto de Modelo (MCP)?\n",
    "\n",
    "El [Protocolo de Contexto de Modelo (MCP)](https://github.com/modelcontextprotocol) es un estándar abierto diseñado para facilitar la integración entre aplicaciones de modelos de lenguaje grande (LLM) y fuentes de datos o herramientas externas. Este protocolo proporciona una forma estandarizada de conectar aplicaciones LLM con el contexto que necesitan, ya sea para desarrollar un IDE basado en IA, mejorar una interfaz de chat o crear flujos de trabajo de IA personalizados.\n",
    "\n",
    "### ¿Por qué necesitamos MCP?\n",
    "\n",
    "En el ecosistema actual de IA, los modelos de lenguaje operan de forma aislada, sin acceso directo a datos actualizados, herramientas específicas o sistemas empresariales. Esto limita su utilidad práctica. MCP resuelve estos desafíos proporcionando:\n",
    "\n",
    "- **Conectividad universal**: Un protocolo común para que los LLMs accedan a cualquier fuente de datos o herramienta\n",
    "- **Seguridad integrada**: Control granular sobre qué datos y funcionalidades están disponibles\n",
    "- **Eficiencia**: Comunicación optimizada entre componentes\n",
    "- **Flexibilidad**: Arquitectura modular que se adapta a diferentes casos de uso\n",
    "\n",
    "### Características principales de MCP\n",
    "\n",
    "#### 1. **Protocolo Agnóstico al Transporte**\n",
    "MCP puede funcionar sobre diferentes medios de comunicación:\n",
    "- **STDIO**: Para aplicaciones locales y scripts\n",
    "- **HTTP/SSE**: Para servicios web y aplicaciones distribuidas\n",
    "- **WebSockets**: Para comunicación bidireccional en tiempo real\n",
    "\n",
    "#### 2. **Tipado Fuerte y Versionado**\n",
    "- Esquemas JSON bien definidos para todos los mensajes\n",
    "- Versionado semántico para compatibilidad hacia atrás\n",
    "- Validación automática de tipos de datos\n",
    "\n",
    "#### 3. **Modelo de Capacidades**\n",
    "Los servidores MCP exponen diferentes tipos de capacidades:\n",
    "- **Herramientas (Tools)**: Funciones que el LLM puede ejecutar\n",
    "- **Recursos (Resources)**: Datos estructurados que el LLM puede consultar\n",
    "- **Prompts**: Plantillas de prompts reutilizables\n",
    "- **Notificaciones**: Eventos en tiempo real\n",
    "\n",
    "#### 4. **Gestión de Sesiones**\n",
    "- Autenticación y autorización integradas\n",
    "- Manejo de estado de sesión\n",
    "- Reconexión automática en caso de fallos\n",
    "\n",
    "### Arquitectura de MCP\n",
    "\n",
    "La arquitectura de MCP sigue un patrón cliente-servidor con componentes bien definidos:\n",
    "\n",
    "```\n",
    "┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐\n",
    "│   Aplicación    │    │   Cliente MCP   │    │  Servidor MCP   │\n",
    "│   LLM (Host)    │◄──►│   (Protocolo)   │◄──►│  (Herramientas) │\n",
    "└─────────────────┘    └─────────────────┘    └─────────────────┘\n",
    "```\n",
    "\n",
    "#### **Host (Aplicación LLM)**\n",
    "La aplicación que utiliza un modelo de lenguaje y necesita acceso a contexto externo:\n",
    "- Claude Desktop, ChatGPT, interfaces personalizadas\n",
    "- IDEs con funcionalidades de IA\n",
    "- Asistentes virtuales empresariales\n",
    "\n",
    "#### **Cliente MCP**\n",
    "Componente que maneja la comunicación con servidores MCP:\n",
    "- Descubrimiento de capacidades disponibles\n",
    "- Gestión de múltiples conexiones de servidor\n",
    "- Enrutamiento de solicitudes y respuestas\n",
    "- Cacheo de datos frecuentemente utilizados\n",
    "\n",
    "#### **Servidor MCP**\n",
    "Aplicación que expone herramientas y recursos:\n",
    "- APIs de datos (bases de datos, servicios web)\n",
    "- Herramientas de sistema (sistemas de archivos, comandos)\n",
    "- Servicios empresariales (CRM, ERP, herramientas de productividad)\n",
    "\n",
    "### Flujo de Comunicación MCP\n",
    "\n",
    "#### 1. **Inicialización**\n",
    "```\n",
    "Host → Cliente: \"Conectar a servidor weather\"\n",
    "Cliente → Servidor: initialize(capabilities)\n",
    "Servidor → Cliente: capabilities_available(tools, resources)\n",
    "Cliente → Host: \"Herramientas disponibles: get_weather\"\n",
    "```\n",
    "\n",
    "#### 2. **Ejecución de Herramienta**\n",
    "```\n",
    "Host → Cliente: \"Ejecutar get_weather('Madrid')\"\n",
    "Cliente → Servidor: call_tool(name=\"get_weather\", args={\"city\": \"Madrid\"})\n",
    "Servidor → Cliente: tool_result({\"temperature\": 18.5, \"description\": \"Clear\"})\n",
    "Cliente → Host: \"Temperatura en Madrid: 18.5°C, despejado\"\n",
    "```\n",
    "\n",
    "#### 3. **Acceso a Recursos**\n",
    "```\n",
    "Host → Cliente: \"Obtener recurso database/users\"\n",
    "Cliente → Servidor: read_resource(uri=\"database/users\")\n",
    "Servidor → Cliente: resource_content(data=user_list)\n",
    "Cliente → Host: [Datos de usuarios disponibles para el LLM]\n",
    "```\n",
    "\n",
    "### Casos de Uso Comunes\n",
    "\n",
    "#### **Aplicaciones Empresariales**\n",
    "- **CRM Inteligente**: \"Muéstrame el resumen de todas las oportunidades de venta de este trimestre\"\n",
    "- **Análisis de Datos**: \"Genera un reporte de rendimiento basado en nuestras métricas de producción\"\n",
    "- **Gestión de Proyectos**: \"¿Qué tareas están bloqueadas y quién las puede resolver?\"\n",
    "\n",
    "#### **Desarrollo de Software**\n",
    "- **IDE Inteligente**: \"Refactoriza esta función para mejorar su rendimiento\"\n",
    "- **Code Review**: \"Identifica posibles vulnerabilidades de seguridad en este código\"\n",
    "- **Documentación**: \"Genera documentación automática para esta API\"\n",
    "\n",
    "#### **Análisis e Investigación**\n",
    "- **Investigación de Mercado**: \"Compara las tendencias de precios en diferentes mercados\"\n",
    "- **Análisis Financiero**: \"Evalúa el riesgo de esta cartera de inversión\"\n",
    "- **Monitoreo de Sistemas**: \"¿Hay alguna anomalía en los logs del servidor?\"\n",
    "\n",
    "### Beneficios Clave de MCP\n",
    "\n",
    "#### **Para Desarrolladores**\n",
    "- **Desarrollo Rápido**: SDKs completos y bien documentados\n",
    "- **Reutilización**: Un servidor puede servir múltiples aplicaciones\n",
    "- **Seguridad**: Patrones de seguridad incorporados por defecto\n",
    "- **Escalabilidad**: Arquitectura diseñada para crecer\n",
    "\n",
    "#### **Para Organizaciones**\n",
    "- **Reducción de Costos**: Evita desarrollo de integraciones personalizadas\n",
    "- **Time-to-Market**: Implementación más rápida de funcionalidades de IA\n",
    "- **Control de Datos**: Mantiene datos sensibles bajo control organizacional\n",
    "- **Interoperabilidad**: Funciona con diferentes proveedores de LLM\n",
    "\n",
    "#### **Para Usuarios Finales**\n",
    "- **Precisión**: Acceso a información actualizada y contextual\n",
    "- **Productividad**: Automatización de tareas complejas\n",
    "- **Inteligencia**: Respuestas más relevantes y útiles\n",
    "- **Conectividad**: Un punto de acceso a múltiples sistemas\n",
    "\n",
    "### Empezando con MCP\n",
    "\n",
    "Para comenzar a trabajar con MCP, puedes acceder a los siguientes recursos:\n",
    "\n",
    "- [Documentación oficial](https://modelcontextprotocol.io): Guías y tutoriales para ayudarte a empezar.\n",
    "- [Especificación del protocolo](https://spec.modelcontextprotocol.io): Detalles técnicos del protocolo.\n",
    "- SDKs disponibles: Herramientas para comenzar a construir en diferentes lenguajes de programación:\n",
    "  - [TypeScript SDK](https://github.com/modelcontextprotocol/typescript-sdk)\n",
    "  - [Python SDK](https://github.com/modelcontextprotocol/python-sdk)\n",
    "  - [Java SDK](https://github.com/modelcontextprotocol/java-sdk)\n",
    "  - [Kotlin SDK](https://github.com/modelcontextprotocol/kotlin-sdk)\n",
    "  - [C# SDK](https://github.com/modelcontextprotocol/csharp-sdk)\n",
    "\n",
    "### Estructura del proyecto MCP\n",
    "\n",
    "El repositorio de MCP en GitHub está organizado de la siguiente manera:\n",
    "- `specification`: Especificación y documentación del protocolo.\n",
    "- `typescript-sdk`: Implementación en TypeScript.\n",
    "- `python-sdk`: Implementación en Python.\n",
    "- `java-sdk`: Implementación en Java.\n",
    "- `kotlin-sdk`: Implementación en Kotlin.\n",
    "- `csharp-sdk`: Implementación en C#.\n",
    "- `docs`: Documentación y guías de usuario.\n",
    "- `create-kotlin-server`: Servidor de muestra en Kotlin.\n",
    "- `servers`: Lista de servidores MCP mantenidos.\n",
    "\n",
    "Para más información y para contribuir al proyecto, visita el [repositorio oficial de MCP en GitHub](https://github.com/modelcontextprotocol)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c015d1b-09a0-4673-82f3-0d0f98506721",
   "metadata": {},
   "source": [
    "## Ejemplo práctico: Servidor MCP Weather\n",
    "\n",
    "Para entender mejor cómo funciona MCP en la práctica, vamos a construir un servidor que proporciona información meteorológica. Este ejemplo demuestra los conceptos fundamentales del protocolo y cómo crear herramientas que los LLMs pueden utilizar de forma dinámica.\n",
    "\n",
    "### ¿Qué hace nuestro servidor Weather?\n",
    "\n",
    "Nuestro servidor MCP Weather expone una herramienta llamada `get_weather` que permite a los modelos de lenguaje consultar información meteorológica en tiempo real para cualquier ciudad del mundo. Esta herramienta:\n",
    "\n",
    "- Acepta el nombre de una ciudad como parámetro\n",
    "- Utiliza la API de geocodificación de OpenWeatherMap para obtener coordenadas\n",
    "- Consulta datos meteorológicos actuales (temperatura y descripción)\n",
    "- Devuelve la información estructurada en formato JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad09e32-914a-4f53-b787-007f989ac0ad",
   "metadata": {},
   "source": [
    "### Configuración del proyecto\n",
    "\n",
    "Antes de comenzar, necesitamos instalar las dependencias y configurar nuestra API key:\n",
    "\n",
    "```bash\n",
    "# Instalar dependencias\n",
    "uv add mcp python-dotenv requests\n",
    "\n",
    "# Obtener API key gratuita de OpenWeatherMap\n",
    "# Visita: https://openweathermap.org/api\n",
    "```\n",
    "\n",
    "Crea un archivo `.env` en tu directorio de proyecto:\n",
    "```env\n",
    "OPENWEATHER_API_KEY=tu_api_key_aquí\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e509db0e-99c1-46c2-a8c1-bd01e59bf8e6",
   "metadata": {},
   "source": [
    "### Implementación del servidor\n",
    "\n",
    "```python\n",
    "from typing import Any\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import os\n",
    "import asyncio\n",
    "\n",
    "print(\"Inicializando MCP Weather...\")\n",
    "\n",
    "# Cargar variables de entorno\n",
    "load_dotenv()\n",
    "\n",
    "# Obtener API KEY\n",
    "api_key = os.getenv(\"OPENWEATHER_API_KEY\")\n",
    "\n",
    "# Inicializar servidor FastMCP\n",
    "mcp = FastMCP(\"weather\", dependencies=[\"requests\"])\n",
    "print(\"Servidor MCP creado con dependencias: requests\")\n",
    "\n",
    "@mcp.tool()\n",
    "def get_weather(city: str) -> dict[str, Any]:\n",
    "    \"\"\"Get current weather for a location\"\"\"\n",
    "    try:\n",
    "        api_key = os.getenv(\"OPENWEATHER_API_KEY\")\n",
    "        \n",
    "        if not api_key:\n",
    "            raise ValueError(\"OPENWEATHER_API_KEY no encontrada en las variables de entorno\")\n",
    "        \n",
    "        # Obtener coordenadas de la ciudad\n",
    "        geo_url = f\"http://api.openweathermap.org/geo/1.0/direct?q={city}&limit=1&appid={api_key}\"\n",
    "        geo_response = requests.get(geo_url)\n",
    "        geo_response.raise_for_status()\n",
    "        geo_data = geo_response.json()\n",
    "        \n",
    "        if not geo_data:\n",
    "            raise ValueError(f\"No se encontró la ciudad: {city}\")\n",
    "        \n",
    "        lat = geo_data[0][\"lat\"]\n",
    "        lon = geo_data[0][\"lon\"]\n",
    "        \n",
    "        # Obtener datos meteorológicos\n",
    "        weather_url = f\"https://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&appid={api_key}&units=metric\"\n",
    "        weather_response = requests.get(weather_url)\n",
    "        weather_response.raise_for_status()\n",
    "        weather_data = weather_response.json()\n",
    "        \n",
    "        temperature = weather_data[\"main\"][\"temp\"]\n",
    "        description = weather_data[\"weather\"][0][\"main\"]\n",
    "        \n",
    "        return {\n",
    "            \"location\": city,\n",
    "            \"temperature\": temperature,\n",
    "            \"description\": description,\n",
    "        }\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error de red: {e}\")\n",
    "        return {\"error\": f\"Error de red: {str(e)}\"}\n",
    "    except (KeyError, IndexError) as e:\n",
    "        print(f\"Error procesando datos de la API: {e}\")\n",
    "        return {\"error\": f\"Error procesando datos de la API: {str(e)}\"}\n",
    "    except ValueError as e:\n",
    "        print(f\"Error de validación: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "    except Exception as e:\n",
    "        print(f\"Error inesperado: {e}\")\n",
    "        return {\"error\": f\"Error inesperado: {str(e)}\"}\n",
    "\n",
    "def main():\n",
    "    \"\"\"Función principal para ejecutar el servidor MCP\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SERVIDOR MCP WEATHER\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Herramientas disponibles:\")\n",
    "    print(\"   • get_weather(city) - Obtiene clima actual\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        print(\"Iniciando servidor MCP...\")\n",
    "        print(\"Presiona Ctrl+C para detener\")\n",
    "        print(\"Esperando conexiones MCP...\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "        \n",
    "        mcp.run()\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nServidor detenido por el usuario\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError al ejecutar el servidor: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ac4399-b52c-4a81-bb69-5920b560cb09",
   "metadata": {},
   "source": [
    "### Cómo ejecutar el servidor\n",
    "\n",
    "1. **Guarda el código** en un archivo llamado `mcp_weather.py`\n",
    "2. **Ejecuta el servidor** desde terminal:\n",
    "   ```bash\n",
    "    python mcp_weather.py\n",
    "   ```\n",
    "3. **Verifica que esté funcionando** - deberías ver:\n",
    "   ```\n",
    "    SERVIDOR MCP WEATHER\n",
    "    ============================================================\n",
    "    Herramientas disponibles:\n",
    "       • get_weather(city) - Obtiene clima actual\n",
    "    ============================================================\n",
    "    Iniciando servidor MCP...\n",
    "    Presiona Ctrl+C para detener\n",
    "    Esperando conexiones MCP...\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b140b4ea-45be-40e0-b28d-01dcbee03ac3",
   "metadata": {},
   "source": [
    "\n",
    "### Conceptos clave de MCP demostrados\n",
    "\n",
    "Este ejemplo ilustra varios conceptos fundamentales del protocolo MCP:\n",
    "\n",
    "1. **Herramientas (Tools)**: El decorador `@mcp.tool()` registra la función `get_weather` como una herramienta disponible para los LLMs.\n",
    "\n",
    "2. **Tipado fuerte**: Utilizamos type hints de Python para definir claramente los parámetros de entrada (`city: str`) y el tipo de retorno (`dict[str, Any]`).\n",
    "\n",
    "3. **Manejo de errores**: Implementamos un manejo robusto de errores que devuelve información útil tanto para el desarrollador como para el LLM.\n",
    "\n",
    "4. **Comunicación estándar**: El servidor utiliza el protocolo MCP estándar para comunicarse con aplicaciones cliente.\n",
    "\n",
    "5. **Recursos externos**: Demostramos cómo integrar APIs externas (OpenWeatherMap) de forma segura usando variables de entorno.\n",
    "\n",
    "### Casos de uso prácticos\n",
    "\n",
    "Una vez que el servidor esté ejecutándose, un LLM conectado podría utilizar esta herramienta para:\n",
    "\n",
    "- \"¿Qué temperatura hace en Madrid ahora mismo?\"\n",
    "- \"Compara el clima entre Londres, París y Berlín\"\n",
    "- \"Necesito saber si llueve en São Paulo para mi reunión\"\n",
    "- \"¿Debo llevar abrigo si viajo a Tokyo mañana?\"\n",
    "\n",
    "### Próximos pasos\n",
    "\n",
    "Este ejemplo te proporciona una base sólida para crear tus propios servidores MCP. Algunas ideas para expandir el proyecto:\n",
    "\n",
    "- Agregar pronósticos de varios días\n",
    "- Incluir mapas meteorológicos\n",
    "- Implementar alertas meteorológicas\n",
    "- Cachear respuestas para mejorar rendimiento\n",
    "\n",
    "Con este ejemplo práctico, puedes ver cómo MCP facilita la creación de herramientas especializadas que extienden las capacidades de los modelos de lenguaje de forma modular y reutilizable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aefbf8-0392-41e3-a1d2-aa528dfa6316",
   "metadata": {},
   "source": [
    "## Ejemplo práctico: Cliente MCP Weather\n",
    "\n",
    "El **Model Context Protocol (MCP)** es un protocolo estándar que permite la comunicación entre clientes y servidores mediante JSON-RPC 2.0. En este ejemplo, demostraremos cómo un cliente Python se comunica con un servidor MCP para obtener información meteorológica de ciudades paraguayas.\n",
    "\n",
    "### Arquitectura de la Comunicación\n",
    "\n",
    "```\n",
    "Cliente MCP ←→ JSON-RPC 2.0 ←→ Servidor MCP\n",
    "    ↓                              ↓\n",
    "Análisis con                   API del Clima\n",
    "  OpenAI                      (OpenWeatherMap)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3417cf-04bd-450a-bbec-a93b88476120",
   "metadata": {},
   "source": [
    "Crea un archivo `.env` en tu directorio de proyecto:\n",
    "```env\n",
    "OPENAI_API_KEY=tu_api_key_aquí\n",
    "```\n",
    "\n",
    "### Implementación del cliente\n",
    "\n",
    "```python\n",
    "import asyncio\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class ExternalMCPClient:\n",
    "    def __init__(self, server_command=None):\n",
    "        self.openai = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "        self.server_process = None\n",
    "        self.message_id = 1\n",
    "        self.server_command = server_command or [sys.executable, \"mcp_weather.py\"]\n",
    "        \n",
    "        # Ciudades del Paraguay\n",
    "        self.paraguay_cities = [\n",
    "            \"Asunción\", \n",
    "            \"Ciudad del Este\", \n",
    "            \"San Lorenzo\",\n",
    "            \"Luque\",\n",
    "            \"Capiatá\",\n",
    "            \"Lambaré\",\n",
    "            \"Fernando de la Mora\"\n",
    "        ]\n",
    "\n",
    "    async def connect_to_external_server(self):\n",
    "        \"\"\"\n",
    "        Se conecta a un servidor MCP externo que YA ESTÁ EJECUTÁNDOSE.\n",
    "        Inicia el servidor como subproceso para comunicación STDIO.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(\"Conectando a servidor MCP externo...\")\n",
    "            \n",
    "            # CONECTAR al servidor existente via STDIO\n",
    "            self.server_process = await asyncio.create_subprocess_exec(\n",
    "                *self.server_command,\n",
    "                stdin=asyncio.subprocess.PIPE,\n",
    "                stdout=asyncio.subprocess.PIPE,\n",
    "                stderr=asyncio.subprocess.PIPE\n",
    "            )\n",
    "            \n",
    "            print(\"Conectado al servidor MCP\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error conectando al servidor: {e}\")\n",
    "            return False\n",
    "\n",
    "    async def send_request(self, method: str, params: dict = None) -> dict:\n",
    "        \"\"\"Enviar solicitud JSON-RPC al servidor\"\"\"\n",
    "        try:\n",
    "\n",
    "            message = {\n",
    "                \"jsonrpc\": \"2.0\",\n",
    "                \"id\": self.message_id,\n",
    "                \"method\": method\n",
    "            }\n",
    "        \n",
    "            if params:\n",
    "                message[\"params\"] = params\n",
    "                \n",
    "            self.message_id += 1\n",
    "\n",
    "            # Enviar\n",
    "            message_str = json.dumps(message) + \"\\n\"\n",
    "            # Descomentar para mostrar mensaje enviado\n",
    "            # print(f\"Enviando solicitud: {json.dumps(message, indent=2)}\")\n",
    "            self.server_process.stdin.write(message_str.encode())\n",
    "            await self.server_process.stdin.drain()\n",
    "\n",
    "            # Recibir\n",
    "            response_line = await self.server_process.stdout.readline()\n",
    "            if not response_line:\n",
    "                raise Exception(\"Sin respuesta del servidor\")\n",
    "                \n",
    "            return json.loads(response_line.decode().strip())\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error en comunicación: {e}\")\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "    async def send_notification(self, method: str, params: dict = None):\n",
    "        \"\"\"Enviar una notificación JSON-RPC (sin id, no espera respuesta)\"\"\"\n",
    "        try:\n",
    "            message = {\n",
    "                \"jsonrpc\": \"2.0\",\n",
    "                \"method\": method\n",
    "            }\n",
    "            if params is not None:\n",
    "                message[\"params\"] = params\n",
    "\n",
    "            message_str = json.dumps(message) + \"\\n\"\n",
    "            # Descomentar para mostrar notificacion enviado\n",
    "            # print(f\"Enviando notificacion: {json.dumps(message, indent=2)}\")\n",
    "            self.server_process.stdin.write(message_str.encode())\n",
    "            await self.server_process.stdin.drain()\n",
    "        except Exception as e:\n",
    "            print(f\"Error enviando notificación: {e}\")\n",
    "\n",
    "    async def initialize(self):\n",
    "        \"\"\"Handshake inicial con servidor\"\"\"\n",
    "        try:\n",
    "            print(\"Inicializando protocolo MCP...\")\n",
    "            \n",
    "            init_params = {\n",
    "                \"protocolVersion\": \"2024-11-05\",\n",
    "                \"capabilities\": {\"roots\": {\"listChanged\": True}, \"sampling\": {}},\n",
    "                \"clientInfo\": {\n",
    "                    \"name\": \"weather-client\",\n",
    "                    \"version\": \"1.0.0\"\n",
    "                }\n",
    "            }\n",
    "\n",
    "            response = await self.send_request(\"initialize\", init_params)\n",
    "            # Descomentar para mostrar respuesta\n",
    "            # print(\"Respuesta inicial:\", json.dumps(response, indent=2))\n",
    "            \n",
    "            if \"error\" in response:\n",
    "                print(f\"Error en inicialización: {response['error']}\")\n",
    "                return False\n",
    "                \n",
    "            # Notificación de inicialización\n",
    "            await self.send_notification(\"notifications/initialized\")\n",
    "            \n",
    "            print(\"Protocolo MCP inicializado\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error en inicialización: {e}\")\n",
    "            return False\n",
    "\n",
    "    async def list_tools(self):\n",
    "        \"\"\"Listar herramientas del servidor\"\"\"\n",
    "        try:\n",
    "            print(\"Obteniendo herramientas disponibles...\")\n",
    "            \n",
    "            response = await self.send_request(\"tools/list\")\n",
    "            # Descomentar para mostrar respuesta\n",
    "            # print(\"Respuesta de herramientas:\", json.dumps(response, indent=2))\n",
    "            \n",
    "            if \"error\" in response:\n",
    "                print(f\"Error: {response['error']}\")\n",
    "                return []\n",
    "                \n",
    "            if \"result\" in response and \"tools\" in response[\"result\"]:\n",
    "                tools = response[\"result\"][\"tools\"]\n",
    "                print(f\"Herramientas encontradas: {len(tools)}\")\n",
    "                \n",
    "                for tool in tools:\n",
    "                    print(f\"  - {tool['name']}: {tool.get('description', 'Sin descripción')}\")\n",
    "                \n",
    "                return [tool[\"name\"] for tool in tools]\n",
    "            \n",
    "            return []\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error listando herramientas: {e}\")\n",
    "            return []\n",
    "\n",
    "    async def call_tool(self, name: str, arguments: dict):\n",
    "        \"\"\"Ejecutar herramienta en servidor externo\"\"\"\n",
    "        try:\n",
    "            # Descomentar para mostrar llamada a herramienta\n",
    "            #print(f\"Ejecutando: {name} con args: {arguments}\")\n",
    "            \n",
    "            params = {\n",
    "                \"name\": name,\n",
    "                \"arguments\": arguments\n",
    "            }\n",
    "            \n",
    "            response = await self.send_request(\"tools/call\", params)\n",
    "            \n",
    "            if \"error\" in response:\n",
    "                print(f\"Error en herramienta: {response['error']}\")\n",
    "                return {\"error\": response[\"error\"]}\n",
    "                \n",
    "            if \"result\" in response:\n",
    "                result = response[\"result\"]\n",
    "                \n",
    "                # Extraer contenido\n",
    "                if \"content\" in result and result[\"content\"]:\n",
    "                    content = result[\"content\"][0]\n",
    "                    if content[\"type\"] == \"text\":\n",
    "                        try:\n",
    "                            return json.loads(content[\"text\"])\n",
    "                        except json.JSONDecodeError:\n",
    "                            return {\"result\": content[\"text\"]}\n",
    "                \n",
    "                return result\n",
    "            \n",
    "            return {\"error\": \"Respuesta inesperada\"}\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error ejecutando herramienta: {e}\")\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "    async def get_paraguay_weather(self):\n",
    "        \"\"\"Obtener clima de Paraguay usando servidor\"\"\"\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(\"CONSULTANDO CLIMA VIA SERVIDOR MCP\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        weather_data = []\n",
    "        \n",
    "        for city in self.paraguay_cities:\n",
    "            print(f\"\\nConsultando: {city}\")\n",
    "            \n",
    "            result = await self.call_tool(\"get_weather\", {\"city\": city})\n",
    "            \n",
    "            if \"error\" not in result:\n",
    "                weather_data.append(result)\n",
    "                temp = result.get(\"temperature\", \"N/A\")\n",
    "                desc = result.get(\"description\", \"N/A\")\n",
    "                print(f\"{city}: {temp}°C - {desc}\")\n",
    "            else:\n",
    "                print(f\"{city}: {result['error']}\")\n",
    "                weather_data.append({\n",
    "                    \"location\": city,\n",
    "                    \"error\": result[\"error\"]\n",
    "                })\n",
    "                \n",
    "        return weather_data\n",
    "\n",
    "    async def analyze_with_openai(self, weather_data):\n",
    "        \"\"\"Análisis con OpenAI\"\"\"\n",
    "        try:            \n",
    "            prompt = \"Analiza estos datos meteorológicos de Paraguay:\\n\\n\"\n",
    "            \n",
    "            for data in weather_data:\n",
    "                if \"error\" not in data:\n",
    "                    prompt += f\"- {data.get('location', 'N/A')}: {data.get('temperature', 'N/A')}°C, \"\n",
    "                    prompt += f\"{data.get('description', 'N/A')}\\n\"\n",
    "                else:\n",
    "                    prompt += f\"- {data.get('location', 'N/A')}: Error en consulta\\n\"\n",
    "            \n",
    "            prompt += \"\\nProporciona:\\n1. Resumen del clima\\n2. Ciudad más calurosa/fresca\\n\"\n",
    "            prompt += \"3. Recomendaciones\\n4. Patrones observados\"\n",
    "            \n",
    "            response = self.openai.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"Eres un meteorólogo experto en Paraguay. Analiza datos de forma clara y útil.\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt\n",
    "                    }\n",
    "                ],\n",
    "                max_tokens=600,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            \n",
    "            return response.choices[0].message.content\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error con OpenAI: {str(e)}\"\n",
    "\n",
    "    async def disconnect(self):\n",
    "        \"\"\"Desconectar del servidor\"\"\"\n",
    "        try:\n",
    "            if self.server_process:\n",
    "                print(\"\\nDesconectando del servidor MCP...\")\n",
    "                self.server_process.terminate()\n",
    "                await self.server_process.wait()\n",
    "                print(\"Desconectado\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error desconectando: {e}\")\n",
    "\n",
    "async def main():\n",
    "    \"\"\"\n",
    "    Función principal para cliente de servidor externo\n",
    "    \"\"\"\n",
    "    client = None\n",
    "    \n",
    "    try:\n",
    "        print(\"=\" * 40)\n",
    "        print(\"CLIENTE MCP WEATHER\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        # Verificar variables de entorno\n",
    "        if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "            print(\"Error: OPENAI_API_KEY no encontrada\")\n",
    "            return\n",
    "        \n",
    "        # Crear cliente\n",
    "        client = ExternalMCPClient()\n",
    "        \n",
    "        # Conectar a servidor externo\n",
    "        if not await client.connect_to_external_server():\n",
    "            print(\"No se pudo conectar al servidor MCP\")\n",
    "            print(\"Asegúrate de que esté ejecutándose en otro terminal\")\n",
    "            return\n",
    "        \n",
    "        # Inicializar protocolo\n",
    "        if not await client.initialize():\n",
    "            return\n",
    "        \n",
    "        # Listar herramientas\n",
    "        tools = await client.list_tools()\n",
    "        if not tools:\n",
    "            print(\"No hay herramientas disponibles\")\n",
    "            return\n",
    "        \n",
    "        # Obtener clima\n",
    "        weather_data = await client.get_paraguay_weather()\n",
    "        \n",
    "        # Analizar con OpenAI\n",
    "        analysis = await client.analyze_with_openai(weather_data)\n",
    "        \n",
    "        # Mostrar resultados\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(\"ANÁLISIS METEOROLÓGICO\")\n",
    "        print(f\"{'='*50}\")\n",
    "        print(analysis)\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        print(\"\\nCliente completado exitosamente!\")\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nProceso interrumpido\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    finally:\n",
    "        if client:\n",
    "            await client.disconnect()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0109375a-a307-4db8-bdf3-6395690ed1f9",
   "metadata": {},
   "source": [
    "### Cómo ejecutar el cliente\n",
    "\n",
    "1. **Guarda el código** en un archivo llamado `mcp_client_weather.py`\n",
    "2. **Ejecuta el cliente** desde terminal:\n",
    "   ```bash\n",
    "    python mcp_client_weather.py\n",
    "   ```\n",
    "3. **Verifica que esté funcionando** - deberías ver:\n",
    "   ```\n",
    "    CLIENTE MCP WEATHER\n",
    "    ========================================\n",
    "    Conectando a servidor MCP externo...\n",
    "    Conectado al servidor MCP\n",
    "    Inicializando protocolo MCP...\n",
    "    Protocolo MCP inicializado\n",
    "    Obteniendo herramientas disponibles...\n",
    "    Herramientas encontradas: 1\n",
    "      - get_weather: Get current weather for a location\n",
    "    \n",
    "    ==================================================\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173682ae-6b4d-442e-a826-46ae80fb108a",
   "metadata": {},
   "source": [
    "### Componentes del Cliente\n",
    "\n",
    "#### 1. Clase ExternalMCPClient\n",
    "\n",
    "La clase principal maneja toda la comunicación con el servidor MCP:\n",
    "\n",
    "```python\n",
    "class ExternalMCPClient:\n",
    "    def __init__(self, server_command=None):\n",
    "        self.openai = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "        self.server_process = None\n",
    "        self.message_id = 1\n",
    "        self.server_command = server_command or [sys.executable, \"mcp_weather.py\"]\n",
    "```\n",
    "\n",
    "**Componentes clave:**\n",
    "- **openai**: Cliente para análisis posterior\n",
    "- **server_process**: Proceso del servidor MCP\n",
    "- **message_id**: Identificador único para mensajes JSON-RPC\n",
    "- **server_command**: Comando para ejecutar el servidor\n",
    "\n",
    "#### 2. Conexión al Servidor\n",
    "\n",
    "```python\n",
    "async def connect_to_external_server(self):\n",
    "    self.server_process = await asyncio.create_subprocess_exec(\n",
    "        *self.server_command,\n",
    "        stdin=asyncio.subprocess.PIPE,\n",
    "        stdout=asyncio.subprocess.PIPE,\n",
    "        stderr=asyncio.subprocess.PIPE\n",
    "    )\n",
    "```\n",
    "\n",
    "**Proceso:**\n",
    "1. Inicia el servidor como subproceso\n",
    "2. Establece comunicación vía STDIO (entrada/salida estándar)\n",
    "3. Configura tuberías para intercambio de mensajes\n",
    "\n",
    "### Protocolo de Comunicación JSON-RPC 2.0\n",
    "\n",
    "#### Estructura de Mensajes\n",
    "\n",
    "**Solicitud (Request)**\n",
    "```json\n",
    "{\n",
    "  \"jsonrpc\": \"2.0\",\n",
    "  \"id\": 1,\n",
    "  \"method\": \"initialize\",\n",
    "  \"params\": {\n",
    "    \"protocolVersion\": \"2024-11-05\",\n",
    "    \"capabilities\": {...},\n",
    "    \"clientInfo\": {...}\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Respuesta (Response)**\n",
    "```json\n",
    "{\n",
    "  \"jsonrpc\": \"2.0\",\n",
    "  \"id\": 1,\n",
    "  \"result\": {\n",
    "    \"protocolVersion\": \"2024-11-05\",\n",
    "    \"capabilities\": {...},\n",
    "    \"serverInfo\": {...}\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Notificación (Notification)**\n",
    "```json\n",
    "{\n",
    "  \"jsonrpc\": \"2.0\",\n",
    "  \"method\": \"notifications/initialized\"\n",
    "}\n",
    "```\n",
    "\n",
    "### Flujo de Ejecución Completo\n",
    "\n",
    "#### Paso 1: Inicialización del Protocolo\n",
    "\n",
    "**Código:**\n",
    "```python\n",
    "async def initialize(self):\n",
    "    init_params = {\n",
    "        \"protocolVersion\": \"2024-11-05\",\n",
    "        \"capabilities\": {\"roots\": {\"listChanged\": True}, \"sampling\": {}},\n",
    "        \"clientInfo\": {\"name\": \"weather-client\", \"version\": \"1.0.0\"}\n",
    "    }\n",
    "    response = await self.send_request(\"initialize\", init_params)\n",
    "```\n",
    "\n",
    "**Salida del ejemplo:**\n",
    "```\n",
    "Inicializando protocolo MCP...\n",
    "Enviando solicitud: {\n",
    "  \"jsonrpc\": \"2.0\",\n",
    "  \"id\": 1,\n",
    "  \"method\": \"initialize\",\n",
    "  \"params\": {\n",
    "    \"protocolVersion\": \"2024-11-05\",\n",
    "    \"capabilities\": {\n",
    "      \"roots\": {\"listChanged\": true},\n",
    "      \"sampling\": {}\n",
    "    },\n",
    "    \"clientInfo\": {\n",
    "      \"name\": \"weather-client\",\n",
    "      \"version\": \"1.0.0\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Respuesta del servidor:**\n",
    "```json\n",
    "{\n",
    "  \"jsonrpc\": \"2.0\",\n",
    "  \"id\": 1,\n",
    "  \"result\": {\n",
    "    \"protocolVersion\": \"2024-11-05\",\n",
    "    \"capabilities\": {\n",
    "      \"experimental\": {},\n",
    "      \"prompts\": {\"listChanged\": false},\n",
    "      \"resources\": {\"subscribe\": false, \"listChanged\": false},\n",
    "      \"tools\": {\"listChanged\": false}\n",
    "    },\n",
    "    \"serverInfo\": {\n",
    "      \"name\": \"weather\",\n",
    "      \"version\": \"1.12.3\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "#### Paso 2: Descubrimiento de Herramientas\n",
    "\n",
    "**Código:**\n",
    "```python\n",
    "async def list_tools(self):\n",
    "    response = await self.send_request(\"tools/list\")\n",
    "    return [tool[\"name\"] for tool in response[\"result\"][\"tools\"]]\n",
    "```\n",
    "\n",
    "**Salida:**\n",
    "```\n",
    "Herramientas encontradas: 1\n",
    "  - get_weather: Get current weather for a location\n",
    "```\n",
    "\n",
    "**Esquema de la herramienta:**\n",
    "```json\n",
    "{\n",
    "  \"name\": \"get_weather\",\n",
    "  \"description\": \"Get current weather for a location\",\n",
    "  \"inputSchema\": {\n",
    "    \"properties\": {\n",
    "      \"city\": {\"title\": \"City\", \"type\": \"string\"}\n",
    "    },\n",
    "    \"required\": [\"city\"],\n",
    "    \"type\": \"object\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "#### Paso 3: Ejecución de Herramientas\n",
    "\n",
    "**Código:**\n",
    "```python\n",
    "async def call_tool(self, name: str, arguments: dict):\n",
    "    params = {\"name\": name, \"arguments\": arguments}\n",
    "    response = await self.send_request(\"tools/call\", params)\n",
    "```\n",
    "\n",
    "**Ejemplo de llamada:**\n",
    "```\n",
    "Consultando: Asunción\n",
    "Ejecutando: get_weather con args: {'city': 'Asunción'}\n",
    "```\n",
    "\n",
    "**Mensaje JSON-RPC:**\n",
    "```json\n",
    "{\n",
    "  \"jsonrpc\": \"2.0\",\n",
    "  \"id\": 3,\n",
    "  \"method\": \"tools/call\",\n",
    "  \"params\": {\n",
    "    \"name\": \"get_weather\",\n",
    "    \"arguments\": {\n",
    "      \"city\": \"Asunción\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Resultado:**\n",
    "```\n",
    "Asunción: 14.42°C - Clear\n",
    "```\n",
    "\n",
    "### Análisis Generado por OpenAI\n",
    "\n",
    "El cliente procesa automáticamente los datos y genera un análisis completo que incluye:\n",
    "\n",
    "1. **Resumen del clima general**\n",
    "2. **Identificación de temperaturas extremas**\n",
    "   - Ciudad más calurosa: San Lorenzo (21.11°C)\n",
    "   - Ciudad más fresca: Ciudad del Este (11.34°C)\n",
    "3. **Recomendaciones prácticas**\n",
    "4. **Patrones meteorológicos observados**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "149260cc-ba51-4c1e-9a44-d75238a6c4d5",
   "metadata": {},
   "source": [
    "========================================\n",
    "CLIENTE MCP WEATHER\n",
    "========================================\n",
    "Conectando a servidor MCP externo...\n",
    "Conectado al servidor MCP\n",
    "Inicializando protocolo MCP...\n",
    "Protocolo MCP inicializado\n",
    "Obteniendo herramientas disponibles...\n",
    "Herramientas encontradas: 1\n",
    "  - get_weather: Get current weather for a location\n",
    "\n",
    "==================================================\n",
    "CONSULTANDO CLIMA VIA SERVIDOR MCP\n",
    "==================================================\n",
    "\n",
    "Consultando: Asunción\n",
    "Asunción: 13.86°C - Clear\n",
    "\n",
    "Consultando: Ciudad del Este\n",
    "Ciudad del Este: 11.34°C - Clear\n",
    "\n",
    "Consultando: San Lorenzo\n",
    "San Lorenzo: 21.11°C - Clouds\n",
    "\n",
    "Consultando: Luque\n",
    "Luque: 13.89°C - Clear\n",
    "\n",
    "Consultando: Capiatá\n",
    "Capiatá: 13.55°C - Clear\n",
    "\n",
    "Consultando: Lambaré\n",
    "Lambaré: 13.62°C - Clear\n",
    "\n",
    "Consultando: Fernando de la Mora\n",
    "Fernando de la Mora: 13.45°C - Clear\n",
    "\n",
    "==================================================\n",
    "ANÁLISIS METEOROLÓGICO\n",
    "==================================================\n",
    "### Análisis Meteorológico de Paraguay\n",
    "\n",
    "#### 1. Resumen del clima\n",
    "En la fecha analizada, las temperaturas en varias ciudades de Paraguay muestran un rango de entre 11.34°C y 21.11°C. La mayoría de las ciudades reportan cielos despejados, lo que sugiere condiciones de buen tiempo y una alta radiación solar. Sin embargo, San Lorenzo presenta un cielo nublado, lo que podría influir en su temperatura y confort.\n",
    "\n",
    "#### 2. Ciudad más calurosa/fresca\n",
    "- **Ciudad más calurosa:** San Lorenzo, con una temperatura de **21.11°C** y condiciones de nubes.\n",
    "- **Ciudad más fresca:** Ciudad del Este, con una temperatura de **11.34°C** y condiciones despejadas.\n",
    "\n",
    "#### 3. Recomendaciones\n",
    "- **Para las ciudades con temperaturas más frescas (como Ciudad del Este y Asunción):** Se sugiere el uso de ropa de abrigo ligero, especialmente en las horas de la mañana y la noche.\n",
    "- **Para San Lorenzo:** Aunque la temperatura es más alta, el cielo nublado podría significar una sensación térmica más fresca. Se recomienda llevar una chaqueta ligera.\n",
    "- **Actividades al aire libre:** Aprovechar las condiciones despejadas en la mayoría de las ciudades para realizar actividades al aire libre, especialmente en las horas centrales del día cuando las temperaturas son más agradables.\n",
    "\n",
    "#### 4. Patrones observados\n",
    "- La mayoría de las ciudades reportan temperaturas en un rango relativamente fresco, lo que indica un clima estable y posiblemente la influencia de un sistema de alta presión en la región.\n",
    "- La variación en la temperatura en San Lorenzo, que es significativamente más alta, sugiere un microclima local que puede estar influenciado por la urbanización o la proximidad a cuerpos de agua.\n",
    "- La predominancia de cielos despejados en la mayoría de las ciudades puede ser una señal de que se están acercando condiciones más cálidas en el futuro cercano.\n",
    "\n",
    "En conclusión, el clima en Paraguay muestra una tendencia estable con temperaturas frescas y cielos en su mayoría despejados, lo que permite aprovechar el buen tiempo.\n",
    "==================================================\n",
    "\n",
    "Cliente completado exitosamente!\n",
    "\n",
    "Desconectando del servidor MCP...\n",
    "Desconectado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e83a27e-ae99-4556-ab87-810e74d70dcf",
   "metadata": {},
   "source": [
    "El ejemplo demuestra cómo MCP facilita la comunicación estructurada entre componentes, permitiendo:\n",
    "\n",
    "1. **Conexión transparente** a servicios externos\n",
    "2. **Descubrimiento automático** de funcionalidades\n",
    "3. **Ejecución remota** de herramientas especializadas\n",
    "4. **Procesamiento inteligente** de resultados\n",
    "\n",
    "Esta arquitectura proporciona una base sólida para construir aplicaciones distribuidas y modulares, manteniendo la simplicidad en la interfaz de comunicación."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
