# Semana 1 - LLM Zoomcamp

Este documento recopila mis apuntes y recursos para la **Semana 1** del curso LLM Zoomcamp.

## ðŸ“ Notas de la teorÃ­a

### DefiniciÃ³n de LLM 

Un LLM (Large Language Model) es un modelo de lenguaje basado en redes neuronales profundas, entrenado para predecir el siguiente token (una palabra, parte de una palabra o sÃ­mbolo) en una secuencia de texto. A partir de grandes volÃºmenes de datos textuales, aprende patrones sintÃ¡cticos, semÃ¡nticos y contextuales, lo que le permite generar respuestas coherentes, relevantes y con apariencia humana.

Los LLM mÃ¡s avanzados estÃ¡n compuestos por miles de millones o incluso billones de parÃ¡metros. Estos parÃ¡metros â€”los pesos de la red neuronalâ€” representan el conocimiento adquirido durante el entrenamiento.

El rendimiento de un LLM depende en gran medida de tres factores:
* La cantidad y diversidad del corpus de entrenamiento
* La escala del modelo (nÃºmero de parÃ¡metros)
* Y su arquitectura, siendo el Transformer la base de los modelos modernos.

**Â¿CÃ³mo predice tokens un LLM?**
1. Se introduce un prompt o secuencia inicial de texto.
2. El modelo calcula la probabilidad de cada posible token que podrÃ­a continuar la secuencia.
3. Se selecciona el token mÃ¡s probable (o uno entre los mÃ¡s probables, usando tÃ©cnicas como muestreo o top-k).
4. El token elegido se agrega al texto y el proceso se repite hasta completar la respuesta.

### DefiniciÃ³n de RAG

### Crear entorno

Para crear y gestionar el entorno de Python de este proyecto se utiliza `uv`, una herramienta moderna que combina gestiÃ³n de entornos virtuales y resoluciÃ³n de dependencias de forma rÃ¡pida y eficiente.

Este enfoque reemplaza el uso tradicional de herramientas como `venv`, `pip` y `virtualenv`, ofreciendo una experiencia mÃ¡s simple y veloz.

â„¹ï¸ Para mÃ¡s detalles sobre cÃ³mo instalar y utilizar uv, consulta el archivo [`working-with-uv.md`](../docs/working-with-uv.md)

Una vez instalado `uv`, puedes crear el entorno virtual e instalar todas las dependencias necesarias con un solo comando:

```bash
uv venv && uv sync
```

Esto crearÃ¡ un entorno virtual en el directorio del proyecto y sincronizarÃ¡ las librerÃ­as especificadas en el archivo `pyproject.toml`.

### Usando la API de OpenAI





## ðŸ’» Ejemplos de cÃ³digo

```python
# Ejemplo: cargar un modelo GPT simple
```

## ðŸ”— Lectura recomendada
Recomendado para profundizar en los conceptos clave y ampliar tu comprensiÃ³n
* [Del prompt a la respuesta: el poder de los Large Language Models](https://medium.com/@j92riquelme/del-prompt-a-la-respuesta-el-poder-de-los-large-language-models-b4a28663fed9)
* [Â¿QuÃ© son los modelos de lenguaje de grandes (LLM)?](https://azure.microsoft.com/es-es/resources/cloud-computing-dictionary/what-are-large-language-models-llms)
* [Introduction to Large Language Models](https://developers.google.com/machine-learning/resources/intro-llms)

## ðŸ”— Videos recomendados
SelecciÃ³n de videos para reforzar visualmente los temas abordados
* [IntroducciÃ³n a la IA generativa](https://www.youtube.com/watch?v=tNBvUvsScAA&t=1s)
* [IntroducciÃ³n a los modelos de lenguaje grandes](https://www.youtube.com/watch?v=Vi0ODh3ncxw&t=3s)
* [Introduction to Responsible AI](https://www.youtube.com/watch?v=JbluXe6QpxM&t=4s)


## Cursos adicionales recomendados
Recursos complementarios para seguir aprendiendo y fortaleciendo tus habilidades.

* [Introduction to Generative AI Learning Path](https://www.cloudskillsboost.google/paths/118)


---

> ðŸ“Œ **Nota:** este repositorio complementa el curso **LLM Zoomcamp** de [DataTalks.Club](https://datatalks.club/), y contiene notas, lecturas, videos, ejemplos y recursos adicionales.  
> Para acceder al contenido oficial del curso, visita el [**repositorio principal en GitHub**](https://github.com/DataTalksClub/llm-zoomcamp).
